{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPSyUeoxE4Zn"
      },
      "source": [
        "**Reinforcement learning for Trading:**\n",
        "\n",
        "The training enviromenent used is:\n",
        "https://github.com/AminHP/gym-anytrading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lEVD8pNVFgj7",
        "outputId": "244f66f0-fb67-4435-9e42-af0cddaee79e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.9.1'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfk8sE9aIUGk",
        "outputId": "77ec636c-b903-4c79-9594-a39e16d26437"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow==1.15.0 in /usr/local/lib/python3.7/dist-packages (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.37.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.47.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.14.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.21.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.0.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.8.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.0) (1.5.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: stable-baselines[mpi]==2.10.2 in /usr/local/lib/python3.7/dist-packages (2.10.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.2) (4.6.0.66)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.2) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.2) (1.3.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.2) (1.1.0)\n",
            "Requirement already satisfied: cloudpickle>=0.5.5 in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.2) (1.5.0)\n",
            "Requirement already satisfied: gym[atari,classic_control]>=0.11 in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.2) (0.21.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.2) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.2) (1.21.6)\n",
            "Requirement already satisfied: mpi4py in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.2) (3.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.1 in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.2) (4.12.0)\n",
            "Collecting pyglet>=1.4.0\n",
            "  Downloading pyglet-1.5.26-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ale-py~=0.7.1 in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.2) (0.7.5)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.1->gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.2) (5.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.1->gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.2) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.1->gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.2) (3.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.2) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.2) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.2) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.2) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->stable-baselines[mpi]==2.10.2) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines[mpi]==2.10.2) (2022.2.1)\n",
            "Installing collected packages: pyglet\n",
            "Successfully installed pyglet-1.5.26\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym==0.21.0 in /usr/local/lib/python3.7/dist-packages (0.21.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.1 in /usr/local/lib/python3.7/dist-packages (from gym==0.21.0) (4.12.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym==0.21.0) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym==0.21.0) (1.21.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.1->gym==0.21.0) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.1->gym==0.21.0) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==1.15.0\n",
        "!pip install stable-baselines[mpi]==2.10.2\n",
        "!pip install gym==0.21.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCewLA3jGi-f",
        "outputId": "cc9d5b5c-4f33-48c2-83c3-b6e9708f8b0e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/stable_baselines/__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n",
            "  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n"
          ]
        }
      ],
      "source": [
        "# Gym \n",
        "import gym\n",
        "import gym_anytrading\n",
        "\n",
        "# Stable baselines - rl stuff\n",
        "from stable_baselines.common.vec_env import DummyVecEnv\n",
        "from stable_baselines import A2C\n",
        "\n",
        "# Processing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMXO82GlMRbB"
      },
      "source": [
        "**1. Bring in Marketwatch Carriage Services Inc. Data**\n",
        "\n",
        "https://www.marketwatch.com/investing/stock/csv/download-data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "DQC7pOwDMXQC"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/Download Data - STOCK_US_XNYS_CSV (4).csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tGe7EGlbMdZO",
        "outputId": "4c053066-83d1-411f-abda-4321ab5d1bd6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-84689fcb-f980-4f0c-833a-7aabfcb945a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>08/25/2022</td>\n",
              "      <td>38.91</td>\n",
              "      <td>38.91</td>\n",
              "      <td>38.11</td>\n",
              "      <td>38.38</td>\n",
              "      <td>46,951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>08/24/2022</td>\n",
              "      <td>38.51</td>\n",
              "      <td>39.10</td>\n",
              "      <td>38.13</td>\n",
              "      <td>38.56</td>\n",
              "      <td>70,144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>08/23/2022</td>\n",
              "      <td>38.22</td>\n",
              "      <td>39.15</td>\n",
              "      <td>38.22</td>\n",
              "      <td>38.77</td>\n",
              "      <td>71,610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>08/22/2022</td>\n",
              "      <td>39.64</td>\n",
              "      <td>39.66</td>\n",
              "      <td>37.93</td>\n",
              "      <td>38.27</td>\n",
              "      <td>105,002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>08/19/2022</td>\n",
              "      <td>40.15</td>\n",
              "      <td>40.68</td>\n",
              "      <td>39.69</td>\n",
              "      <td>40.18</td>\n",
              "      <td>118,481</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84689fcb-f980-4f0c-833a-7aabfcb945a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-84689fcb-f980-4f0c-833a-7aabfcb945a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-84689fcb-f980-4f0c-833a-7aabfcb945a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         Date   Open   High    Low  Close   Volume\n",
              "0  08/25/2022  38.91  38.91  38.11  38.38   46,951\n",
              "1  08/24/2022  38.51  39.10  38.13  38.56   70,144\n",
              "2  08/23/2022  38.22  39.15  38.22  38.77   71,610\n",
              "3  08/22/2022  39.64  39.66  37.93  38.27  105,002\n",
              "4  08/19/2022  40.15  40.68  39.69  40.18  118,481"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkzPMm_2NDdy",
        "outputId": "635b2cb4-662c-445e-8c78-b303541f7f7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Date      datetime64[ns]\n",
              "Open             float64\n",
              "High             float64\n",
              "Low              float64\n",
              "Close            float64\n",
              "Volume            object\n",
              "dtype: object"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Convert Date to dateTime to work with the gym_anything enviroment\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "YVqPRqXWNLes",
        "outputId": "e6791843-1e33-491e-e860-be95a35f302d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-76243d16-2484-4a33-b761-3a61b8a51e38\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-08-25</th>\n",
              "      <td>38.91</td>\n",
              "      <td>38.91</td>\n",
              "      <td>38.11</td>\n",
              "      <td>38.38</td>\n",
              "      <td>46,951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-24</th>\n",
              "      <td>38.51</td>\n",
              "      <td>39.10</td>\n",
              "      <td>38.13</td>\n",
              "      <td>38.56</td>\n",
              "      <td>70,144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-23</th>\n",
              "      <td>38.22</td>\n",
              "      <td>39.15</td>\n",
              "      <td>38.22</td>\n",
              "      <td>38.77</td>\n",
              "      <td>71,610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-22</th>\n",
              "      <td>39.64</td>\n",
              "      <td>39.66</td>\n",
              "      <td>37.93</td>\n",
              "      <td>38.27</td>\n",
              "      <td>105,002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-19</th>\n",
              "      <td>40.15</td>\n",
              "      <td>40.68</td>\n",
              "      <td>39.69</td>\n",
              "      <td>40.18</td>\n",
              "      <td>118,481</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76243d16-2484-4a33-b761-3a61b8a51e38')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-76243d16-2484-4a33-b761-3a61b8a51e38 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-76243d16-2484-4a33-b761-3a61b8a51e38');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             Open   High    Low  Close   Volume\n",
              "Date                                           \n",
              "2022-08-25  38.91  38.91  38.11  38.38   46,951\n",
              "2022-08-24  38.51  39.10  38.13  38.56   70,144\n",
              "2022-08-23  38.22  39.15  38.22  38.77   71,610\n",
              "2022-08-22  39.64  39.66  37.93  38.27  105,002\n",
              "2022-08-19  40.15  40.68  39.69  40.18  118,481"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Set Date column as Index\n",
        "df.set_index('Date', inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "jkcbACpFNij-"
      },
      "outputs": [],
      "source": [
        "env = gym.make('stocks-v0', df=df, frame_bound=(5,235), window_size=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnfWr5UoNkxI",
        "outputId": "e4698646-295d-467e-e1a5-2f097cdfb1ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 3.838e+01,  0.000e+00],\n",
              "       [ 3.856e+01,  1.800e-01],\n",
              "       [ 3.877e+01,  2.100e-01],\n",
              "       [ 3.827e+01, -5.000e-01],\n",
              "       [ 4.018e+01,  1.910e+00],\n",
              "       [ 4.041e+01,  2.300e-01],\n",
              "       [ 4.063e+01,  2.200e-01],\n",
              "       [ 4.063e+01,  0.000e+00],\n",
              "       [ 4.103e+01,  4.000e-01],\n",
              "       [ 3.985e+01, -1.180e+00],\n",
              "       [ 3.804e+01, -1.810e+00],\n",
              "       [ 3.852e+01,  4.800e-01],\n",
              "       [ 3.638e+01, -2.140e+00],\n",
              "       [ 3.582e+01, -5.600e-01],\n",
              "       [ 3.668e+01,  8.600e-01],\n",
              "       [ 3.424e+01, -2.440e+00],\n",
              "       [ 3.600e+01,  1.760e+00],\n",
              "       [ 3.866e+01,  2.660e+00],\n",
              "       [ 3.770e+01, -9.600e-01],\n",
              "       [ 3.628e+01, -1.420e+00],\n",
              "       [ 3.684e+01,  5.600e-01],\n",
              "       [ 4.405e+01,  7.210e+00],\n",
              "       [ 4.367e+01, -3.800e-01],\n",
              "       [ 4.291e+01, -7.600e-01],\n",
              "       [ 4.254e+01, -3.700e-01],\n",
              "       [ 4.252e+01, -2.000e-02],\n",
              "       [ 4.125e+01, -1.270e+00],\n",
              "       [ 4.111e+01, -1.400e-01],\n",
              "       [ 3.960e+01, -1.510e+00],\n",
              "       [ 4.039e+01,  7.900e-01],\n",
              "       [ 3.932e+01, -1.070e+00],\n",
              "       [ 3.908e+01, -2.400e-01],\n",
              "       [ 3.917e+01,  9.000e-02],\n",
              "       [ 3.937e+01,  2.000e-01],\n",
              "       [ 3.998e+01,  6.100e-01],\n",
              "       [ 3.994e+01, -4.000e-02],\n",
              "       [ 3.954e+01, -4.000e-01],\n",
              "       [ 3.993e+01,  3.900e-01],\n",
              "       [ 4.023e+01,  3.000e-01],\n",
              "       [ 3.965e+01, -5.800e-01],\n",
              "       [ 3.901e+01, -6.400e-01],\n",
              "       [ 3.934e+01,  3.300e-01],\n",
              "       [ 3.981e+01,  4.700e-01],\n",
              "       [ 3.940e+01, -4.100e-01],\n",
              "       [ 3.756e+01, -1.840e+00],\n",
              "       [ 3.688e+01, -6.800e-01],\n",
              "       [ 3.774e+01,  8.600e-01],\n",
              "       [ 3.564e+01, -2.100e+00],\n",
              "       [ 3.598e+01,  3.400e-01],\n",
              "       [ 3.838e+01,  2.400e+00],\n",
              "       [ 3.791e+01, -4.700e-01],\n",
              "       [ 3.734e+01, -5.700e-01],\n",
              "       [ 3.957e+01,  2.230e+00],\n",
              "       [ 4.092e+01,  1.350e+00],\n",
              "       [ 4.110e+01,  1.800e-01],\n",
              "       [ 4.189e+01,  7.900e-01],\n",
              "       [ 4.137e+01, -5.200e-01],\n",
              "       [ 4.064e+01, -7.300e-01],\n",
              "       [ 4.160e+01,  9.600e-01],\n",
              "       [ 4.087e+01, -7.300e-01],\n",
              "       [ 4.037e+01, -5.000e-01],\n",
              "       [ 4.042e+01,  5.000e-02],\n",
              "       [ 4.005e+01, -3.700e-01],\n",
              "       [ 3.916e+01, -8.900e-01],\n",
              "       [ 3.880e+01, -3.600e-01],\n",
              "       [ 3.871e+01, -9.000e-02],\n",
              "       [ 3.833e+01, -3.800e-01],\n",
              "       [ 3.850e+01,  1.700e-01],\n",
              "       [ 3.868e+01,  1.800e-01],\n",
              "       [ 4.067e+01,  1.990e+00],\n",
              "       [ 3.952e+01, -1.150e+00],\n",
              "       [ 3.952e+01,  0.000e+00],\n",
              "       [ 3.949e+01, -3.000e-02],\n",
              "       [ 3.899e+01, -5.000e-01],\n",
              "       [ 3.929e+01,  3.000e-01],\n",
              "       [ 4.007e+01,  7.800e-01],\n",
              "       [ 4.130e+01,  1.230e+00],\n",
              "       [ 4.149e+01,  1.900e-01],\n",
              "       [ 4.334e+01,  1.850e+00],\n",
              "       [ 4.157e+01, -1.770e+00],\n",
              "       [ 4.215e+01,  5.800e-01],\n",
              "       [ 4.289e+01,  7.400e-01],\n",
              "       [ 4.487e+01,  1.980e+00],\n",
              "       [ 4.862e+01,  3.750e+00],\n",
              "       [ 4.848e+01, -1.400e-01],\n",
              "       [ 4.973e+01,  1.250e+00],\n",
              "       [ 4.959e+01, -1.400e-01],\n",
              "       [ 5.227e+01,  2.680e+00],\n",
              "       [ 5.299e+01,  7.200e-01],\n",
              "       [ 5.314e+01,  1.500e-01],\n",
              "       [ 5.221e+01, -9.300e-01],\n",
              "       [ 5.188e+01, -3.300e-01],\n",
              "       [ 5.200e+01,  1.200e-01],\n",
              "       [ 5.153e+01, -4.700e-01],\n",
              "       [ 5.088e+01, -6.500e-01],\n",
              "       [ 5.162e+01,  7.400e-01],\n",
              "       [ 5.161e+01, -1.000e-02],\n",
              "       [ 5.111e+01, -5.000e-01],\n",
              "       [ 5.262e+01,  1.510e+00],\n",
              "       [ 5.233e+01, -2.900e-01],\n",
              "       [ 5.249e+01,  1.600e-01],\n",
              "       [ 5.333e+01,  8.400e-01],\n",
              "       [ 5.285e+01, -4.800e-01],\n",
              "       [ 5.292e+01,  7.000e-02],\n",
              "       [ 5.422e+01,  1.300e+00],\n",
              "       [ 5.486e+01,  6.400e-01],\n",
              "       [ 5.459e+01, -2.700e-01],\n",
              "       [ 5.335e+01, -1.240e+00],\n",
              "       [ 5.517e+01,  1.820e+00],\n",
              "       [ 5.525e+01,  8.000e-02],\n",
              "       [ 5.606e+01,  8.100e-01],\n",
              "       [ 5.413e+01, -1.930e+00],\n",
              "       [ 5.465e+01,  5.200e-01],\n",
              "       [ 5.336e+01, -1.290e+00],\n",
              "       [ 5.261e+01, -7.500e-01],\n",
              "       [ 5.116e+01, -1.450e+00],\n",
              "       [ 5.164e+01,  4.800e-01],\n",
              "       [ 5.049e+01, -1.150e+00],\n",
              "       [ 5.068e+01,  1.900e-01],\n",
              "       [ 5.066e+01, -2.000e-02],\n",
              "       [ 5.121e+01,  5.500e-01],\n",
              "       [ 5.057e+01, -6.400e-01],\n",
              "       [ 5.081e+01,  2.400e-01],\n",
              "       [ 4.989e+01, -9.200e-01],\n",
              "       [ 4.921e+01, -6.800e-01],\n",
              "       [ 5.034e+01,  1.130e+00],\n",
              "       [ 4.898e+01, -1.360e+00],\n",
              "       [ 4.948e+01,  5.000e-01],\n",
              "       [ 4.949e+01,  1.000e-02],\n",
              "       [ 4.950e+01,  1.000e-02],\n",
              "       [ 4.932e+01, -1.800e-01],\n",
              "       [ 5.109e+01,  1.770e+00],\n",
              "       [ 5.161e+01,  5.200e-01],\n",
              "       [ 5.080e+01, -8.100e-01],\n",
              "       [ 5.051e+01, -2.900e-01],\n",
              "       [ 5.131e+01,  8.000e-01],\n",
              "       [ 5.229e+01,  9.800e-01],\n",
              "       [ 5.090e+01, -1.390e+00],\n",
              "       [ 5.007e+01, -8.300e-01],\n",
              "       [ 4.869e+01, -1.380e+00],\n",
              "       [ 4.889e+01,  2.000e-01],\n",
              "       [ 4.935e+01,  4.600e-01],\n",
              "       [ 4.983e+01,  4.800e-01],\n",
              "       [ 5.032e+01,  4.900e-01],\n",
              "       [ 4.875e+01, -1.570e+00],\n",
              "       [ 4.813e+01, -6.200e-01],\n",
              "       [ 4.992e+01,  1.790e+00],\n",
              "       [ 5.090e+01,  9.800e-01],\n",
              "       [ 5.283e+01,  1.930e+00],\n",
              "       [ 5.208e+01, -7.500e-01],\n",
              "       [ 5.248e+01,  4.000e-01],\n",
              "       [ 5.466e+01,  2.180e+00],\n",
              "       [ 5.572e+01,  1.060e+00],\n",
              "       [ 5.810e+01,  2.380e+00],\n",
              "       [ 5.819e+01,  9.000e-02],\n",
              "       [ 5.783e+01, -3.600e-01],\n",
              "       [ 5.732e+01, -5.100e-01],\n",
              "       [ 5.740e+01,  8.000e-02],\n",
              "       [ 5.797e+01,  5.700e-01],\n",
              "       [ 5.947e+01,  1.500e+00],\n",
              "       [ 5.912e+01, -3.500e-01],\n",
              "       [ 6.150e+01,  2.380e+00],\n",
              "       [ 6.174e+01,  2.400e-01],\n",
              "       [ 6.444e+01,  2.700e+00],\n",
              "       [ 6.449e+01,  5.000e-02],\n",
              "       [ 6.591e+01,  1.420e+00],\n",
              "       [ 6.499e+01, -9.200e-01],\n",
              "       [ 6.380e+01, -1.190e+00],\n",
              "       [ 6.266e+01, -1.140e+00],\n",
              "       [ 6.308e+01,  4.200e-01],\n",
              "       [ 6.089e+01, -2.190e+00],\n",
              "       [ 5.924e+01, -1.650e+00],\n",
              "       [ 5.942e+01,  1.800e-01],\n",
              "       [ 5.833e+01, -1.090e+00],\n",
              "       [ 5.753e+01, -8.000e-01],\n",
              "       [ 5.563e+01, -1.900e+00],\n",
              "       [ 5.616e+01,  5.300e-01],\n",
              "       [ 5.623e+01,  7.000e-02],\n",
              "       [ 5.544e+01, -7.900e-01],\n",
              "       [ 5.754e+01,  2.100e+00],\n",
              "       [ 5.546e+01, -2.080e+00],\n",
              "       [ 5.451e+01, -9.500e-01],\n",
              "       [ 5.326e+01, -1.250e+00],\n",
              "       [ 5.388e+01,  6.200e-01],\n",
              "       [ 5.207e+01, -1.810e+00],\n",
              "       [ 5.174e+01, -3.300e-01],\n",
              "       [ 5.115e+01, -5.900e-01],\n",
              "       [ 5.295e+01,  1.800e+00],\n",
              "       [ 5.386e+01,  9.100e-01],\n",
              "       [ 5.412e+01,  2.600e-01],\n",
              "       [ 5.264e+01, -1.480e+00],\n",
              "       [ 5.176e+01, -8.800e-01],\n",
              "       [ 5.174e+01, -2.000e-02],\n",
              "       [ 5.186e+01,  1.200e-01],\n",
              "       [ 5.157e+01, -2.900e-01],\n",
              "       [ 5.047e+01, -1.100e+00],\n",
              "       [ 5.042e+01, -5.000e-02],\n",
              "       [ 4.997e+01, -4.500e-01],\n",
              "       [ 4.878e+01, -1.190e+00],\n",
              "       [ 4.949e+01,  7.100e-01],\n",
              "       [ 4.987e+01,  3.800e-01],\n",
              "       [ 4.900e+01, -8.700e-01],\n",
              "       [ 4.844e+01, -5.600e-01],\n",
              "       [ 4.830e+01, -1.400e-01],\n",
              "       [ 4.862e+01,  3.200e-01],\n",
              "       [ 5.078e+01,  2.160e+00],\n",
              "       [ 5.145e+01,  6.700e-01],\n",
              "       [ 5.022e+01, -1.230e+00],\n",
              "       [ 4.396e+01, -6.260e+00],\n",
              "       [ 4.437e+01,  4.100e-01],\n",
              "       [ 4.397e+01, -4.000e-01],\n",
              "       [ 4.423e+01,  2.600e-01],\n",
              "       [ 4.424e+01,  1.000e-02],\n",
              "       [ 4.399e+01, -2.500e-01],\n",
              "       [ 4.415e+01,  1.600e-01],\n",
              "       [ 4.502e+01,  8.700e-01],\n",
              "       [ 4.416e+01, -8.600e-01],\n",
              "       [ 4.495e+01,  7.900e-01],\n",
              "       [ 4.525e+01,  3.000e-01],\n",
              "       [ 4.562e+01,  3.700e-01],\n",
              "       [ 4.557e+01, -5.000e-02],\n",
              "       [ 4.566e+01,  9.000e-02],\n",
              "       [ 4.567e+01,  1.000e-02],\n",
              "       [ 4.517e+01, -5.000e-01],\n",
              "       [ 4.502e+01, -1.500e-01],\n",
              "       [ 4.464e+01, -3.800e-01],\n",
              "       [ 4.516e+01,  5.200e-01],\n",
              "       [ 4.459e+01, -5.700e-01],\n",
              "       [ 4.478e+01,  1.900e-01],\n",
              "       [ 4.447e+01, -3.100e-01],\n",
              "       [ 4.495e+01,  4.800e-01],\n",
              "       [ 4.420e+01, -7.500e-01],\n",
              "       [ 4.390e+01, -3.000e-01],\n",
              "       [ 4.342e+01, -4.800e-01],\n",
              "       [ 4.265e+01, -7.700e-01]])"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Prices and difference in Prices\n",
        "env.signal_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqfeKptOPeWF",
        "outputId": "9b07dcfc-70b0-4356-b19f-646e14ee053e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([38.38, 38.56, 38.77, 38.27, 40.18, 40.41, 40.63, 40.63, 41.03,\n",
              "       39.85, 38.04, 38.52, 36.38, 35.82, 36.68, 34.24, 36.  , 38.66,\n",
              "       37.7 , 36.28, 36.84, 44.05, 43.67, 42.91, 42.54, 42.52, 41.25,\n",
              "       41.11, 39.6 , 40.39, 39.32, 39.08, 39.17, 39.37, 39.98, 39.94,\n",
              "       39.54, 39.93, 40.23, 39.65, 39.01, 39.34, 39.81, 39.4 , 37.56,\n",
              "       36.88, 37.74, 35.64, 35.98, 38.38, 37.91, 37.34, 39.57, 40.92,\n",
              "       41.1 , 41.89, 41.37, 40.64, 41.6 , 40.87, 40.37, 40.42, 40.05,\n",
              "       39.16, 38.8 , 38.71, 38.33, 38.5 , 38.68, 40.67, 39.52, 39.52,\n",
              "       39.49, 38.99, 39.29, 40.07, 41.3 , 41.49, 43.34, 41.57, 42.15,\n",
              "       42.89, 44.87, 48.62, 48.48, 49.73, 49.59, 52.27, 52.99, 53.14,\n",
              "       52.21, 51.88, 52.  , 51.53, 50.88, 51.62, 51.61, 51.11, 52.62,\n",
              "       52.33, 52.49, 53.33, 52.85, 52.92, 54.22, 54.86, 54.59, 53.35,\n",
              "       55.17, 55.25, 56.06, 54.13, 54.65, 53.36, 52.61, 51.16, 51.64,\n",
              "       50.49, 50.68, 50.66, 51.21, 50.57, 50.81, 49.89, 49.21, 50.34,\n",
              "       48.98, 49.48, 49.49, 49.5 , 49.32, 51.09, 51.61, 50.8 , 50.51,\n",
              "       51.31, 52.29, 50.9 , 50.07, 48.69, 48.89, 49.35, 49.83, 50.32,\n",
              "       48.75, 48.13, 49.92, 50.9 , 52.83, 52.08, 52.48, 54.66, 55.72,\n",
              "       58.1 , 58.19, 57.83, 57.32, 57.4 , 57.97, 59.47, 59.12, 61.5 ,\n",
              "       61.74, 64.44, 64.49, 65.91, 64.99, 63.8 , 62.66, 63.08, 60.89,\n",
              "       59.24, 59.42, 58.33, 57.53, 55.63, 56.16, 56.23, 55.44, 57.54,\n",
              "       55.46, 54.51, 53.26, 53.88, 52.07, 51.74, 51.15, 52.95, 53.86,\n",
              "       54.12, 52.64, 51.76, 51.74, 51.86, 51.57, 50.47, 50.42, 49.97,\n",
              "       48.78, 49.49, 49.87, 49.  , 48.44, 48.3 , 48.62, 50.78, 51.45,\n",
              "       50.22, 43.96, 44.37, 43.97, 44.23, 44.24, 43.99, 44.15, 45.02,\n",
              "       44.16, 44.95, 45.25, 45.62, 45.57, 45.66, 45.67, 45.17, 45.02,\n",
              "       44.64, 45.16, 44.59, 44.78, 44.47, 44.95, 44.2 , 43.9 , 43.42,\n",
              "       42.65])"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.prices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REFzBNunPl8F"
      },
      "source": [
        "**2. Build Environment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_dSAF6DP8ay",
        "outputId": "c92ddc93-ebd2-4c8e-bcdb-e995803a6d2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Discrete(2)"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.action_space #it only got sell and buy actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAKl1R4lPhjR",
        "outputId": "4b98a126-0c60-4e2e-9237-f39e91400fd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "info {'total_reward': 4.789999999999992, 'total_profit': 0.47874618970444616, 'position': 0}\n"
          ]
        }
      ],
      "source": [
        "state = env.reset()#initial state\n",
        "while True: \n",
        "    action = env.action_space.sample()#random action\n",
        "    n_state, reward, done, info = env.step(action)#apply action to environment\n",
        "    if done: \n",
        "        print(\"info\", info) #total_profit>1 means we made profit\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "g_iGvKYrPvrM",
        "outputId": "ab89684b-371e-4604-c39d-33db4f44fed4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#plot \n",
        "plt.figure(figsize=(15,6))\n",
        "plt.cla()\n",
        "env.render_all()# red = bad trade, green=good trade\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2BiQG_aRf8f"
      },
      "source": [
        "**3. Build Environment and Train**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "58t1iQfkRfoj"
      },
      "outputs": [],
      "source": [
        "env_maker =lambda: gym.make('stocks-v0', df=df, frame_bound=(5,235), window_size=5)\n",
        "#Wrap the environment inside DummyVecEnv \n",
        "env = DummyVecEnv([env_maker])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "PKkx76xzYqCL"
      },
      "outputs": [],
      "source": [
        "from stable_baselines.common.callbacks import EvalCallback\n",
        "\n",
        "# Use deterministic actions for evaluation\n",
        "eval_callback = EvalCallback(env, best_model_save_path='./logs/',\n",
        "                             log_path='./logs/', eval_freq=500,\n",
        "                             deterministic=True, render=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Go7KYbxRzWu",
        "outputId": "da0ff379-d259-4d95-cfd9-5dc59307571e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| explained_variance | -0.0517  |\n",
            "| fps                | 17       |\n",
            "| nupdates           | 1        |\n",
            "| policy_entropy     | 0.688    |\n",
            "| total_timesteps    | 5        |\n",
            "| value_loss         | 0.734    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=231, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.0669  |\n",
            "| fps                | 266      |\n",
            "| nupdates           | 100      |\n",
            "| policy_entropy     | 0.686    |\n",
            "| total_timesteps    | 500      |\n",
            "| value_loss         | 0.0189   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=731, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.0424   |\n",
            "| fps                | 293      |\n",
            "| nupdates           | 200      |\n",
            "| policy_entropy     | 0.684    |\n",
            "| total_timesteps    | 1000     |\n",
            "| value_loss         | 2.68e-05 |\n",
            "---------------------------------\n",
            "Eval num_timesteps=1231, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.0102   |\n",
            "| fps                | 304      |\n",
            "| nupdates           | 300      |\n",
            "| policy_entropy     | 0.682    |\n",
            "| total_timesteps    | 1500     |\n",
            "| value_loss         | 0.0192   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=1731, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.00156 |\n",
            "| fps                | 311      |\n",
            "| nupdates           | 400      |\n",
            "| policy_entropy     | 0.684    |\n",
            "| total_timesteps    | 2000     |\n",
            "| value_loss         | 3.39     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=2231, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.183   |\n",
            "| fps                | 315      |\n",
            "| nupdates           | 500      |\n",
            "| policy_entropy     | 0.679    |\n",
            "| total_timesteps    | 2500     |\n",
            "| value_loss         | 0.0526   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=2731, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.00769 |\n",
            "| fps                | 318      |\n",
            "| nupdates           | 600      |\n",
            "| policy_entropy     | 0.675    |\n",
            "| total_timesteps    | 3000     |\n",
            "| value_loss         | 0.261    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=3231, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.00743 |\n",
            "| fps                | 320      |\n",
            "| nupdates           | 700      |\n",
            "| policy_entropy     | 0.679    |\n",
            "| total_timesteps    | 3500     |\n",
            "| value_loss         | 0.317    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=3731, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.599    |\n",
            "| fps                | 322      |\n",
            "| nupdates           | 800      |\n",
            "| policy_entropy     | 0.688    |\n",
            "| total_timesteps    | 4000     |\n",
            "| value_loss         | 0.493    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=4231, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.457   |\n",
            "| fps                | 324      |\n",
            "| nupdates           | 900      |\n",
            "| policy_entropy     | 0.684    |\n",
            "| total_timesteps    | 4500     |\n",
            "| value_loss         | 0.692    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=4731, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -12      |\n",
            "| fps                | 325      |\n",
            "| nupdates           | 1000     |\n",
            "| policy_entropy     | 0.687    |\n",
            "| total_timesteps    | 5000     |\n",
            "| value_loss         | 0.329    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=5231, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.0819  |\n",
            "| fps                | 327      |\n",
            "| nupdates           | 1100     |\n",
            "| policy_entropy     | 0.683    |\n",
            "| total_timesteps    | 5500     |\n",
            "| value_loss         | 0.198    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=5731, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.00276  |\n",
            "| fps                | 328      |\n",
            "| nupdates           | 1200     |\n",
            "| policy_entropy     | 0.672    |\n",
            "| total_timesteps    | 6000     |\n",
            "| value_loss         | 1.7      |\n",
            "---------------------------------\n",
            "Eval num_timesteps=6231, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.0105  |\n",
            "| fps                | 328      |\n",
            "| nupdates           | 1300     |\n",
            "| policy_entropy     | 0.631    |\n",
            "| total_timesteps    | 6500     |\n",
            "| value_loss         | 0.15     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=6731, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.0303   |\n",
            "| fps                | 329      |\n",
            "| nupdates           | 1400     |\n",
            "| policy_entropy     | 0.637    |\n",
            "| total_timesteps    | 7000     |\n",
            "| value_loss         | 0.36     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=7231, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.554   |\n",
            "| fps                | 330      |\n",
            "| nupdates           | 1500     |\n",
            "| policy_entropy     | 0.641    |\n",
            "| total_timesteps    | 7500     |\n",
            "| value_loss         | 0.000496 |\n",
            "---------------------------------\n",
            "Eval num_timesteps=7731, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.12     |\n",
            "| fps                | 331      |\n",
            "| nupdates           | 1600     |\n",
            "| policy_entropy     | 0.674    |\n",
            "| total_timesteps    | 8000     |\n",
            "| value_loss         | 0.127    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=8231, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.271    |\n",
            "| fps                | 331      |\n",
            "| nupdates           | 1700     |\n",
            "| policy_entropy     | 0.671    |\n",
            "| total_timesteps    | 8500     |\n",
            "| value_loss         | 0.211    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=8731, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.234    |\n",
            "| fps                | 332      |\n",
            "| nupdates           | 1800     |\n",
            "| policy_entropy     | 0.682    |\n",
            "| total_timesteps    | 9000     |\n",
            "| value_loss         | 0.000876 |\n",
            "---------------------------------\n",
            "Eval num_timesteps=9231, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.71     |\n",
            "| fps                | 332      |\n",
            "| nupdates           | 1900     |\n",
            "| policy_entropy     | 0.618    |\n",
            "| total_timesteps    | 9500     |\n",
            "| value_loss         | 1.07     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=9731, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -3.92    |\n",
            "| fps                | 332      |\n",
            "| nupdates           | 2000     |\n",
            "| policy_entropy     | 0.614    |\n",
            "| total_timesteps    | 10000    |\n",
            "| value_loss         | 0.000275 |\n",
            "---------------------------------\n",
            "Eval num_timesteps=10231, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -7.49    |\n",
            "| fps                | 332      |\n",
            "| nupdates           | 2100     |\n",
            "| policy_entropy     | 0.44     |\n",
            "| total_timesteps    | 10500    |\n",
            "| value_loss         | 0.123    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=10731, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.188    |\n",
            "| fps                | 333      |\n",
            "| nupdates           | 2200     |\n",
            "| policy_entropy     | 0.649    |\n",
            "| total_timesteps    | 11000    |\n",
            "| value_loss         | 0.0619   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=11231, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -5.08    |\n",
            "| fps                | 333      |\n",
            "| nupdates           | 2300     |\n",
            "| policy_entropy     | 0.687    |\n",
            "| total_timesteps    | 11500    |\n",
            "| value_loss         | 0.000624 |\n",
            "---------------------------------\n",
            "Eval num_timesteps=11731, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.0422   |\n",
            "| fps                | 333      |\n",
            "| nupdates           | 2400     |\n",
            "| policy_entropy     | 0.691    |\n",
            "| total_timesteps    | 12000    |\n",
            "| value_loss         | 3.11     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=12231, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.108   |\n",
            "| fps                | 331      |\n",
            "| nupdates           | 2500     |\n",
            "| policy_entropy     | 0.691    |\n",
            "| total_timesteps    | 12500    |\n",
            "| value_loss         | 0.345    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=12731, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.0395   |\n",
            "| fps                | 323      |\n",
            "| nupdates           | 2600     |\n",
            "| policy_entropy     | 0.692    |\n",
            "| total_timesteps    | 13000    |\n",
            "| value_loss         | 0.00256  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=13231, episode_reward=1.46 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.0406  |\n",
            "| fps                | 315      |\n",
            "| nupdates           | 2700     |\n",
            "| policy_entropy     | 0.653    |\n",
            "| total_timesteps    | 13500    |\n",
            "| value_loss         | 0.0817   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=13731, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.0278   |\n",
            "| fps                | 308      |\n",
            "| nupdates           | 2800     |\n",
            "| policy_entropy     | 0.692    |\n",
            "| total_timesteps    | 14000    |\n",
            "| value_loss         | 2.86     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=14231, episode_reward=1.46 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.196    |\n",
            "| fps                | 301      |\n",
            "| nupdates           | 2900     |\n",
            "| policy_entropy     | 0.646    |\n",
            "| total_timesteps    | 14500    |\n",
            "| value_loss         | 0.29     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=14731, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -60.2    |\n",
            "| fps                | 296      |\n",
            "| nupdates           | 3000     |\n",
            "| policy_entropy     | 0.689    |\n",
            "| total_timesteps    | 15000    |\n",
            "| value_loss         | 0.106    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=15231, episode_reward=1.98 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| explained_variance | -718     |\n",
            "| fps                | 289      |\n",
            "| nupdates           | 3100     |\n",
            "| policy_entropy     | 0.685    |\n",
            "| total_timesteps    | 15500    |\n",
            "| value_loss         | 0.00196  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=15731, episode_reward=1.84 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.0821   |\n",
            "| fps                | 285      |\n",
            "| nupdates           | 3200     |\n",
            "| policy_entropy     | 0.691    |\n",
            "| total_timesteps    | 16000    |\n",
            "| value_loss         | 0.214    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=16231, episode_reward=0.79 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "----------------------------------\n",
            "| explained_variance | -3.94e+04 |\n",
            "| fps                | 286       |\n",
            "| nupdates           | 3300      |\n",
            "| policy_entropy     | 0.57      |\n",
            "| total_timesteps    | 16500     |\n",
            "| value_loss         | 0.00167   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=16731, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "----------------------------------\n",
            "| explained_variance | -9.06e+03 |\n",
            "| fps                | 288       |\n",
            "| nupdates           | 3400      |\n",
            "| policy_entropy     | 0.64      |\n",
            "| total_timesteps    | 17000     |\n",
            "| value_loss         | 0.0215    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=17231, episode_reward=0.79 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -37.1    |\n",
            "| fps                | 289      |\n",
            "| nupdates           | 3500     |\n",
            "| policy_entropy     | 0.672    |\n",
            "| total_timesteps    | 17500    |\n",
            "| value_loss         | 0.0165   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=17731, episode_reward=1.46 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.486    |\n",
            "| fps                | 290      |\n",
            "| nupdates           | 3600     |\n",
            "| policy_entropy     | 0.657    |\n",
            "| total_timesteps    | 18000    |\n",
            "| value_loss         | 5.02     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=18231, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.372   |\n",
            "| fps                | 291      |\n",
            "| nupdates           | 3700     |\n",
            "| policy_entropy     | 0.6      |\n",
            "| total_timesteps    | 18500    |\n",
            "| value_loss         | 0.0567   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=18731, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.187    |\n",
            "| fps                | 292      |\n",
            "| nupdates           | 3800     |\n",
            "| policy_entropy     | 0.681    |\n",
            "| total_timesteps    | 19000    |\n",
            "| value_loss         | 1.21     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=19231, episode_reward=0.79 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.00144 |\n",
            "| fps                | 293      |\n",
            "| nupdates           | 3900     |\n",
            "| policy_entropy     | 0.658    |\n",
            "| total_timesteps    | 19500    |\n",
            "| value_loss         | 0.113    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=19731, episode_reward=1.46 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.0341   |\n",
            "| fps                | 294      |\n",
            "| nupdates           | 4000     |\n",
            "| policy_entropy     | 0.692    |\n",
            "| total_timesteps    | 20000    |\n",
            "| value_loss         | 0.382    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=20231, episode_reward=1.68 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.286    |\n",
            "| fps                | 295      |\n",
            "| nupdates           | 4100     |\n",
            "| policy_entropy     | 0.677    |\n",
            "| total_timesteps    | 20500    |\n",
            "| value_loss         | 0.362    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=20731, episode_reward=0.79 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.508    |\n",
            "| fps                | 296      |\n",
            "| nupdates           | 4200     |\n",
            "| policy_entropy     | 0.666    |\n",
            "| total_timesteps    | 21000    |\n",
            "| value_loss         | 0.279    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=21231, episode_reward=1.84 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.359    |\n",
            "| fps                | 296      |\n",
            "| nupdates           | 4300     |\n",
            "| policy_entropy     | 0.679    |\n",
            "| total_timesteps    | 21500    |\n",
            "| value_loss         | 0.00159  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=21731, episode_reward=1.46 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.309   |\n",
            "| fps                | 297      |\n",
            "| nupdates           | 4400     |\n",
            "| policy_entropy     | 0.602    |\n",
            "| total_timesteps    | 22000    |\n",
            "| value_loss         | 0.0468   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=22231, episode_reward=1.68 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.909   |\n",
            "| fps                | 297      |\n",
            "| nupdates           | 4500     |\n",
            "| policy_entropy     | 0.654    |\n",
            "| total_timesteps    | 22500    |\n",
            "| value_loss         | 0.344    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=22731, episode_reward=2.74 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| explained_variance | 0.689    |\n",
            "| fps                | 290      |\n",
            "| nupdates           | 4600     |\n",
            "| policy_entropy     | 0.668    |\n",
            "| total_timesteps    | 23000    |\n",
            "| value_loss         | 0.0871   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=23231, episode_reward=1.16 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.0268   |\n",
            "| fps                | 290      |\n",
            "| nupdates           | 4700     |\n",
            "| policy_entropy     | 0.58     |\n",
            "| total_timesteps    | 23500    |\n",
            "| value_loss         | 0.0188   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=23731, episode_reward=1.16 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.0223   |\n",
            "| fps                | 291      |\n",
            "| nupdates           | 4800     |\n",
            "| policy_entropy     | 0.683    |\n",
            "| total_timesteps    | 24000    |\n",
            "| value_loss         | 0.0553   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=24231, episode_reward=4.46 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| explained_variance | 0.0151   |\n",
            "| fps                | 291      |\n",
            "| nupdates           | 4900     |\n",
            "| policy_entropy     | 0.662    |\n",
            "| total_timesteps    | 24500    |\n",
            "| value_loss         | 0.735    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=24731, episode_reward=4.55 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| explained_variance | 0.567    |\n",
            "| fps                | 292      |\n",
            "| nupdates           | 5000     |\n",
            "| policy_entropy     | 0.647    |\n",
            "| total_timesteps    | 25000    |\n",
            "| value_loss         | 0.222    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=25231, episode_reward=0.79 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.271    |\n",
            "| fps                | 292      |\n",
            "| nupdates           | 5100     |\n",
            "| policy_entropy     | 0.69     |\n",
            "| total_timesteps    | 25500    |\n",
            "| value_loss         | 0.0394   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=25731, episode_reward=0.79 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.491   |\n",
            "| fps                | 293      |\n",
            "| nupdates           | 5200     |\n",
            "| policy_entropy     | 0.665    |\n",
            "| total_timesteps    | 26000    |\n",
            "| value_loss         | 0.000182 |\n",
            "---------------------------------\n",
            "Eval num_timesteps=26231, episode_reward=2.15 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.0122   |\n",
            "| fps                | 293      |\n",
            "| nupdates           | 5300     |\n",
            "| policy_entropy     | 0.619    |\n",
            "| total_timesteps    | 26500    |\n",
            "| value_loss         | 2.03     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=26731, episode_reward=0.79 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.158   |\n",
            "| fps                | 294      |\n",
            "| nupdates           | 5400     |\n",
            "| policy_entropy     | 0.658    |\n",
            "| total_timesteps    | 27000    |\n",
            "| value_loss         | 0.28     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=27231, episode_reward=1.84 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -85.2    |\n",
            "| fps                | 295      |\n",
            "| nupdates           | 5500     |\n",
            "| policy_entropy     | 0.687    |\n",
            "| total_timesteps    | 27500    |\n",
            "| value_loss         | 0.0105   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=27731, episode_reward=3.81 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.0261  |\n",
            "| fps                | 295      |\n",
            "| nupdates           | 5600     |\n",
            "| policy_entropy     | 0.501    |\n",
            "| total_timesteps    | 28000    |\n",
            "| value_loss         | 0.0847   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=28231, episode_reward=4.56 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| explained_variance | -0.00653 |\n",
            "| fps                | 296      |\n",
            "| nupdates           | 5700     |\n",
            "| policy_entropy     | 0.549    |\n",
            "| total_timesteps    | 28500    |\n",
            "| value_loss         | 1.01     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=28731, episode_reward=1.84 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.0389   |\n",
            "| fps                | 297      |\n",
            "| nupdates           | 5800     |\n",
            "| policy_entropy     | 0.647    |\n",
            "| total_timesteps    | 29000    |\n",
            "| value_loss         | 0.166    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=29231, episode_reward=4.12 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.307    |\n",
            "| fps                | 297      |\n",
            "| nupdates           | 5900     |\n",
            "| policy_entropy     | 0.646    |\n",
            "| total_timesteps    | 29500    |\n",
            "| value_loss         | 0.522    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=29731, episode_reward=3.81 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.0877   |\n",
            "| fps                | 298      |\n",
            "| nupdates           | 6000     |\n",
            "| policy_entropy     | 0.673    |\n",
            "| total_timesteps    | 30000    |\n",
            "| value_loss         | 0.181    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=30231, episode_reward=1.68 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.899    |\n",
            "| fps                | 298      |\n",
            "| nupdates           | 6100     |\n",
            "| policy_entropy     | 0.63     |\n",
            "| total_timesteps    | 30500    |\n",
            "| value_loss         | 2.08     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=30731, episode_reward=2.44 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.0275  |\n",
            "| fps                | 299      |\n",
            "| nupdates           | 6200     |\n",
            "| policy_entropy     | 0.615    |\n",
            "| total_timesteps    | 31000    |\n",
            "| value_loss         | 0.385    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=31231, episode_reward=4.16 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.55     |\n",
            "| fps                | 297      |\n",
            "| nupdates           | 6300     |\n",
            "| policy_entropy     | 0.613    |\n",
            "| total_timesteps    | 31500    |\n",
            "| value_loss         | 0.0536   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=31731, episode_reward=2.59 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.0194   |\n",
            "| fps                | 293      |\n",
            "| nupdates           | 6400     |\n",
            "| policy_entropy     | 0.512    |\n",
            "| total_timesteps    | 32000    |\n",
            "| value_loss         | 0.117    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=32231, episode_reward=3.75 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.0311  |\n",
            "| fps                | 292      |\n",
            "| nupdates           | 6500     |\n",
            "| policy_entropy     | 0.559    |\n",
            "| total_timesteps    | 32500    |\n",
            "| value_loss         | 0.0429   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=32731, episode_reward=3.90 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -3.97    |\n",
            "| fps                | 291      |\n",
            "| nupdates           | 6600     |\n",
            "| policy_entropy     | 0.474    |\n",
            "| total_timesteps    | 33000    |\n",
            "| value_loss         | 0.00154  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=33231, episode_reward=2.15 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.553    |\n",
            "| fps                | 292      |\n",
            "| nupdates           | 6700     |\n",
            "| policy_entropy     | 0.556    |\n",
            "| total_timesteps    | 33500    |\n",
            "| value_loss         | 0.161    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=33731, episode_reward=3.19 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.0942  |\n",
            "| fps                | 292      |\n",
            "| nupdates           | 6800     |\n",
            "| policy_entropy     | 0.685    |\n",
            "| total_timesteps    | 34000    |\n",
            "| value_loss         | 0.197    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=34231, episode_reward=4.16 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.00975  |\n",
            "| fps                | 293      |\n",
            "| nupdates           | 6900     |\n",
            "| policy_entropy     | 0.562    |\n",
            "| total_timesteps    | 34500    |\n",
            "| value_loss         | 0.906    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=34731, episode_reward=4.16 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -7.97    |\n",
            "| fps                | 293      |\n",
            "| nupdates           | 7000     |\n",
            "| policy_entropy     | 0.523    |\n",
            "| total_timesteps    | 35000    |\n",
            "| value_loss         | 0.00299  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=35231, episode_reward=2.15 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.387    |\n",
            "| fps                | 294      |\n",
            "| nupdates           | 7100     |\n",
            "| policy_entropy     | 0.536    |\n",
            "| total_timesteps    | 35500    |\n",
            "| value_loss         | 0.546    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=35731, episode_reward=4.54 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.131   |\n",
            "| fps                | 294      |\n",
            "| nupdates           | 7200     |\n",
            "| policy_entropy     | 0.607    |\n",
            "| total_timesteps    | 36000    |\n",
            "| value_loss         | 0.14     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=36231, episode_reward=1.63 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.143   |\n",
            "| fps                | 295      |\n",
            "| nupdates           | 7300     |\n",
            "| policy_entropy     | 0.584    |\n",
            "| total_timesteps    | 36500    |\n",
            "| value_loss         | 0.049    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=36731, episode_reward=2.20 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.232    |\n",
            "| fps                | 295      |\n",
            "| nupdates           | 7400     |\n",
            "| policy_entropy     | 0.48     |\n",
            "| total_timesteps    | 37000    |\n",
            "| value_loss         | 0.392    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=37231, episode_reward=3.81 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.49     |\n",
            "| fps                | 296      |\n",
            "| nupdates           | 7500     |\n",
            "| policy_entropy     | 0.518    |\n",
            "| total_timesteps    | 37500    |\n",
            "| value_loss         | 0.539    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=37731, episode_reward=2.15 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.493   |\n",
            "| fps                | 296      |\n",
            "| nupdates           | 7600     |\n",
            "| policy_entropy     | 0.644    |\n",
            "| total_timesteps    | 38000    |\n",
            "| value_loss         | 0.00195  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=38231, episode_reward=4.17 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.0843   |\n",
            "| fps                | 297      |\n",
            "| nupdates           | 7700     |\n",
            "| policy_entropy     | 0.622    |\n",
            "| total_timesteps    | 38500    |\n",
            "| value_loss         | 0.0639   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=38731, episode_reward=1.89 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.33     |\n",
            "| fps                | 297      |\n",
            "| nupdates           | 7800     |\n",
            "| policy_entropy     | 0.46     |\n",
            "| total_timesteps    | 39000    |\n",
            "| value_loss         | 0.0701   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=39231, episode_reward=4.17 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.683    |\n",
            "| fps                | 297      |\n",
            "| nupdates           | 7900     |\n",
            "| policy_entropy     | 0.575    |\n",
            "| total_timesteps    | 39500    |\n",
            "| value_loss         | 0.328    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=39731, episode_reward=2.15 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.554    |\n",
            "| fps                | 298      |\n",
            "| nupdates           | 8000     |\n",
            "| policy_entropy     | 0.644    |\n",
            "| total_timesteps    | 40000    |\n",
            "| value_loss         | 0.00227  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=40231, episode_reward=4.69 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| explained_variance | -73.3    |\n",
            "| fps                | 298      |\n",
            "| nupdates           | 8100     |\n",
            "| policy_entropy     | 0.61     |\n",
            "| total_timesteps    | 40500    |\n",
            "| value_loss         | 0.00152  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=40731, episode_reward=2.89 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -105     |\n",
            "| fps                | 299      |\n",
            "| nupdates           | 8200     |\n",
            "| policy_entropy     | 0.44     |\n",
            "| total_timesteps    | 41000    |\n",
            "| value_loss         | 0.0197   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=41231, episode_reward=1.84 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.535    |\n",
            "| fps                | 299      |\n",
            "| nupdates           | 8300     |\n",
            "| policy_entropy     | 0.549    |\n",
            "| total_timesteps    | 41500    |\n",
            "| value_loss         | 0.221    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=41731, episode_reward=4.16 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -12.8    |\n",
            "| fps                | 299      |\n",
            "| nupdates           | 8400     |\n",
            "| policy_entropy     | 0.551    |\n",
            "| total_timesteps    | 42000    |\n",
            "| value_loss         | 0.0241   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=42231, episode_reward=1.84 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.127   |\n",
            "| fps                | 300      |\n",
            "| nupdates           | 8500     |\n",
            "| policy_entropy     | 0.678    |\n",
            "| total_timesteps    | 42500    |\n",
            "| value_loss         | 0.19     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=42731, episode_reward=2.71 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.149   |\n",
            "| fps                | 300      |\n",
            "| nupdates           | 8600     |\n",
            "| policy_entropy     | 0.547    |\n",
            "| total_timesteps    | 43000    |\n",
            "| value_loss         | 6.74     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=43231, episode_reward=3.51 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | nan      |\n",
            "| fps                | 301      |\n",
            "| nupdates           | 8700     |\n",
            "| policy_entropy     | 0.414    |\n",
            "| total_timesteps    | 43500    |\n",
            "| value_loss         | 2.06     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=43731, episode_reward=4.16 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.716    |\n",
            "| fps                | 301      |\n",
            "| nupdates           | 8800     |\n",
            "| policy_entropy     | 0.467    |\n",
            "| total_timesteps    | 44000    |\n",
            "| value_loss         | 0.0188   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=44231, episode_reward=2.20 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.088   |\n",
            "| fps                | 301      |\n",
            "| nupdates           | 8900     |\n",
            "| policy_entropy     | 0.578    |\n",
            "| total_timesteps    | 44500    |\n",
            "| value_loss         | 0.108    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=44731, episode_reward=5.06 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| explained_variance | 0.137    |\n",
            "| fps                | 301      |\n",
            "| nupdates           | 9000     |\n",
            "| policy_entropy     | 0.469    |\n",
            "| total_timesteps    | 45000    |\n",
            "| value_loss         | 0.494    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=45231, episode_reward=2.20 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.235    |\n",
            "| fps                | 302      |\n",
            "| nupdates           | 9100     |\n",
            "| policy_entropy     | 0.523    |\n",
            "| total_timesteps    | 45500    |\n",
            "| value_loss         | 0.493    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=45731, episode_reward=1.15 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.155    |\n",
            "| fps                | 302      |\n",
            "| nupdates           | 9200     |\n",
            "| policy_entropy     | 0.283    |\n",
            "| total_timesteps    | 46000    |\n",
            "| value_loss         | 0.219    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=46231, episode_reward=3.41 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -378     |\n",
            "| fps                | 302      |\n",
            "| nupdates           | 9300     |\n",
            "| policy_entropy     | 0.482    |\n",
            "| total_timesteps    | 46500    |\n",
            "| value_loss         | 1.05     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=46731, episode_reward=2.15 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.203    |\n",
            "| fps                | 302      |\n",
            "| nupdates           | 9400     |\n",
            "| policy_entropy     | 0.505    |\n",
            "| total_timesteps    | 47000    |\n",
            "| value_loss         | 0.69     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=47231, episode_reward=2.15 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.675   |\n",
            "| fps                | 302      |\n",
            "| nupdates           | 9500     |\n",
            "| policy_entropy     | 0.471    |\n",
            "| total_timesteps    | 47500    |\n",
            "| value_loss         | 0.0874   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=47731, episode_reward=3.42 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.297    |\n",
            "| fps                | 302      |\n",
            "| nupdates           | 9600     |\n",
            "| policy_entropy     | 0.431    |\n",
            "| total_timesteps    | 48000    |\n",
            "| value_loss         | 0.197    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=48231, episode_reward=5.15 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| explained_variance | 0.227    |\n",
            "| fps                | 303      |\n",
            "| nupdates           | 9700     |\n",
            "| policy_entropy     | 0.408    |\n",
            "| total_timesteps    | 48500    |\n",
            "| value_loss         | 0.0166   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=48731, episode_reward=2.20 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.0965  |\n",
            "| fps                | 303      |\n",
            "| nupdates           | 9800     |\n",
            "| policy_entropy     | 0.516    |\n",
            "| total_timesteps    | 49000    |\n",
            "| value_loss         | 0.876    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=49231, episode_reward=2.15 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -2.64    |\n",
            "| fps                | 303      |\n",
            "| nupdates           | 9900     |\n",
            "| policy_entropy     | 0.399    |\n",
            "| total_timesteps    | 49500    |\n",
            "| value_loss         | 0.941    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=49731, episode_reward=2.20 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.86     |\n",
            "| fps                | 304      |\n",
            "| nupdates           | 10000    |\n",
            "| policy_entropy     | 0.367    |\n",
            "| total_timesteps    | 50000    |\n",
            "| value_loss         | 0.082    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=50231, episode_reward=0.37 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -8.03    |\n",
            "| fps                | 304      |\n",
            "| nupdates           | 10100    |\n",
            "| policy_entropy     | 0.262    |\n",
            "| total_timesteps    | 50500    |\n",
            "| value_loss         | 0.00337  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=50731, episode_reward=4.16 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.0565   |\n",
            "| fps                | 304      |\n",
            "| nupdates           | 10200    |\n",
            "| policy_entropy     | 0.477    |\n",
            "| total_timesteps    | 51000    |\n",
            "| value_loss         | 0.193    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=51231, episode_reward=4.69 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -2.05    |\n",
            "| fps                | 304      |\n",
            "| nupdates           | 10300    |\n",
            "| policy_entropy     | 0.307    |\n",
            "| total_timesteps    | 51500    |\n",
            "| value_loss         | 0.122    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=51731, episode_reward=4.16 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.892    |\n",
            "| fps                | 305      |\n",
            "| nupdates           | 10400    |\n",
            "| policy_entropy     | 0.469    |\n",
            "| total_timesteps    | 52000    |\n",
            "| value_loss         | 0.277    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=52231, episode_reward=2.15 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -7.42    |\n",
            "| fps                | 303      |\n",
            "| nupdates           | 10500    |\n",
            "| policy_entropy     | 0.215    |\n",
            "| total_timesteps    | 52500    |\n",
            "| value_loss         | 0.00707  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=52731, episode_reward=5.06 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.182    |\n",
            "| fps                | 304      |\n",
            "| nupdates           | 10600    |\n",
            "| policy_entropy     | 0.425    |\n",
            "| total_timesteps    | 53000    |\n",
            "| value_loss         | 0.0495   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=53231, episode_reward=3.96 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.441    |\n",
            "| fps                | 304      |\n",
            "| nupdates           | 10700    |\n",
            "| policy_entropy     | 0.403    |\n",
            "| total_timesteps    | 53500    |\n",
            "| value_loss         | 0.708    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=53731, episode_reward=1.89 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.324    |\n",
            "| fps                | 304      |\n",
            "| nupdates           | 10800    |\n",
            "| policy_entropy     | 0.446    |\n",
            "| total_timesteps    | 54000    |\n",
            "| value_loss         | 3.29     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=54231, episode_reward=3.23 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -1.98    |\n",
            "| fps                | 304      |\n",
            "| nupdates           | 10900    |\n",
            "| policy_entropy     | 0.424    |\n",
            "| total_timesteps    | 54500    |\n",
            "| value_loss         | 0.00345  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=54731, episode_reward=3.96 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.115    |\n",
            "| fps                | 304      |\n",
            "| nupdates           | 11000    |\n",
            "| policy_entropy     | 0.413    |\n",
            "| total_timesteps    | 55000    |\n",
            "| value_loss         | 0.0731   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=55231, episode_reward=5.06 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -40.3    |\n",
            "| fps                | 305      |\n",
            "| nupdates           | 11100    |\n",
            "| policy_entropy     | 0.376    |\n",
            "| total_timesteps    | 55500    |\n",
            "| value_loss         | 1.67     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=55731, episode_reward=5.06 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.575    |\n",
            "| fps                | 305      |\n",
            "| nupdates           | 11200    |\n",
            "| policy_entropy     | 0.465    |\n",
            "| total_timesteps    | 56000    |\n",
            "| value_loss         | 1.99     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=56231, episode_reward=4.11 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.0312  |\n",
            "| fps                | 305      |\n",
            "| nupdates           | 11300    |\n",
            "| policy_entropy     | 0.0503   |\n",
            "| total_timesteps    | 56500    |\n",
            "| value_loss         | 0.0433   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=56731, episode_reward=3.97 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.454   |\n",
            "| fps                | 305      |\n",
            "| nupdates           | 11400    |\n",
            "| policy_entropy     | 0.579    |\n",
            "| total_timesteps    | 57000    |\n",
            "| value_loss         | 0.107    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=57231, episode_reward=3.41 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -2.32    |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 11500    |\n",
            "| policy_entropy     | 0.459    |\n",
            "| total_timesteps    | 57500    |\n",
            "| value_loss         | 7.68     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=57731, episode_reward=4.49 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.583    |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 11600    |\n",
            "| policy_entropy     | 0.465    |\n",
            "| total_timesteps    | 58000    |\n",
            "| value_loss         | 7.1      |\n",
            "---------------------------------\n",
            "Eval num_timesteps=58231, episode_reward=2.15 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.738    |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 11700    |\n",
            "| policy_entropy     | 0.442    |\n",
            "| total_timesteps    | 58500    |\n",
            "| value_loss         | 0.0344   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=58731, episode_reward=3.41 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -1.6     |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 11800    |\n",
            "| policy_entropy     | 0.383    |\n",
            "| total_timesteps    | 59000    |\n",
            "| value_loss         | 0.135    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=59231, episode_reward=4.11 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.385    |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 11900    |\n",
            "| policy_entropy     | 0.472    |\n",
            "| total_timesteps    | 59500    |\n",
            "| value_loss         | 0.533    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=59731, episode_reward=5.06 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.558    |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 12000    |\n",
            "| policy_entropy     | 0.379    |\n",
            "| total_timesteps    | 60000    |\n",
            "| value_loss         | 0.156    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=60231, episode_reward=2.56 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.461    |\n",
            "| fps                | 307      |\n",
            "| nupdates           | 12100    |\n",
            "| policy_entropy     | 0.333    |\n",
            "| total_timesteps    | 60500    |\n",
            "| value_loss         | 0.113    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=60731, episode_reward=3.71 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -2.2     |\n",
            "| fps                | 307      |\n",
            "| nupdates           | 12200    |\n",
            "| policy_entropy     | 0.0767   |\n",
            "| total_timesteps    | 61000    |\n",
            "| value_loss         | 0.00759  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=61231, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.828   |\n",
            "| fps                | 307      |\n",
            "| nupdates           | 12300    |\n",
            "| policy_entropy     | 0.0261   |\n",
            "| total_timesteps    | 61500    |\n",
            "| value_loss         | 0.000511 |\n",
            "---------------------------------\n",
            "Eval num_timesteps=61731, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -29.4    |\n",
            "| fps                | 307      |\n",
            "| nupdates           | 12400    |\n",
            "| policy_entropy     | 0.0383   |\n",
            "| total_timesteps    | 62000    |\n",
            "| value_loss         | 2.32e-06 |\n",
            "---------------------------------\n",
            "Eval num_timesteps=62231, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "----------------------------------\n",
            "| explained_variance | -7.38e+03 |\n",
            "| fps                | 308       |\n",
            "| nupdates           | 12500     |\n",
            "| policy_entropy     | 0.0888    |\n",
            "| total_timesteps    | 62500     |\n",
            "| value_loss         | 0.00592   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=62731, episode_reward=0.37 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.167   |\n",
            "| fps                | 308      |\n",
            "| nupdates           | 12600    |\n",
            "| policy_entropy     | 0.311    |\n",
            "| total_timesteps    | 63000    |\n",
            "| value_loss         | 0.118    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=63231, episode_reward=3.41 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.129    |\n",
            "| fps                | 308      |\n",
            "| nupdates           | 12700    |\n",
            "| policy_entropy     | 0.51     |\n",
            "| total_timesteps    | 63500    |\n",
            "| value_loss         | 0.0313   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=63731, episode_reward=3.33 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -38.5    |\n",
            "| fps                | 307      |\n",
            "| nupdates           | 12800    |\n",
            "| policy_entropy     | 0.341    |\n",
            "| total_timesteps    | 64000    |\n",
            "| value_loss         | 0.156    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=64231, episode_reward=1.77 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.273   |\n",
            "| fps                | 305      |\n",
            "| nupdates           | 12900    |\n",
            "| policy_entropy     | 0.349    |\n",
            "| total_timesteps    | 64500    |\n",
            "| value_loss         | 3.13     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=64731, episode_reward=2.75 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.224    |\n",
            "| fps                | 305      |\n",
            "| nupdates           | 13000    |\n",
            "| policy_entropy     | 0.564    |\n",
            "| total_timesteps    | 65000    |\n",
            "| value_loss         | 0.155    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=65231, episode_reward=5.06 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.0734  |\n",
            "| fps                | 305      |\n",
            "| nupdates           | 13100    |\n",
            "| policy_entropy     | 0.359    |\n",
            "| total_timesteps    | 65500    |\n",
            "| value_loss         | 0.26     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=65731, episode_reward=2.45 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -4.26    |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 13200    |\n",
            "| policy_entropy     | 0.365    |\n",
            "| total_timesteps    | 66000    |\n",
            "| value_loss         | 0.0302   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=66231, episode_reward=2.56 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.465   |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 13300    |\n",
            "| policy_entropy     | 0.372    |\n",
            "| total_timesteps    | 66500    |\n",
            "| value_loss         | 32.2     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=66731, episode_reward=3.41 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.38     |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 13400    |\n",
            "| policy_entropy     | 0.417    |\n",
            "| total_timesteps    | 67000    |\n",
            "| value_loss         | 0.0246   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=67231, episode_reward=3.41 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -1.82    |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 13500    |\n",
            "| policy_entropy     | 0.33     |\n",
            "| total_timesteps    | 67500    |\n",
            "| value_loss         | 0.129    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=67731, episode_reward=3.87 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -4.87    |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 13600    |\n",
            "| policy_entropy     | 0.358    |\n",
            "| total_timesteps    | 68000    |\n",
            "| value_loss         | 0.0243   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=68231, episode_reward=2.75 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.435   |\n",
            "| fps                | 306      |\n",
            "| nupdates           | 13700    |\n",
            "| policy_entropy     | 0.368    |\n",
            "| total_timesteps    | 68500    |\n",
            "| value_loss         | 56.8     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=68731, episode_reward=2.56 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.74     |\n",
            "| fps                | 307      |\n",
            "| nupdates           | 13800    |\n",
            "| policy_entropy     | 0.234    |\n",
            "| total_timesteps    | 69000    |\n",
            "| value_loss         | 0.0582   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=69231, episode_reward=2.75 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.213   |\n",
            "| fps                | 307      |\n",
            "| nupdates           | 13900    |\n",
            "| policy_entropy     | 0.423    |\n",
            "| total_timesteps    | 69500    |\n",
            "| value_loss         | 0.0167   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=69731, episode_reward=4.21 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -1.07    |\n",
            "| fps                | 307      |\n",
            "| nupdates           | 14000    |\n",
            "| policy_entropy     | 0.418    |\n",
            "| total_timesteps    | 70000    |\n",
            "| value_loss         | 0.566    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=70231, episode_reward=5.07 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.747   |\n",
            "| fps                | 307      |\n",
            "| nupdates           | 14100    |\n",
            "| policy_entropy     | 0.414    |\n",
            "| total_timesteps    | 70500    |\n",
            "| value_loss         | 114      |\n",
            "---------------------------------\n",
            "Eval num_timesteps=70731, episode_reward=5.07 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.436   |\n",
            "| fps                | 307      |\n",
            "| nupdates           | 14200    |\n",
            "| policy_entropy     | 0.408    |\n",
            "| total_timesteps    | 71000    |\n",
            "| value_loss         | 0.0256   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=71231, episode_reward=3.97 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.296   |\n",
            "| fps                | 307      |\n",
            "| nupdates           | 14300    |\n",
            "| policy_entropy     | 0.401    |\n",
            "| total_timesteps    | 71500    |\n",
            "| value_loss         | 0.229    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=71731, episode_reward=3.97 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -1.38    |\n",
            "| fps                | 308      |\n",
            "| nupdates           | 14400    |\n",
            "| policy_entropy     | 0.649    |\n",
            "| total_timesteps    | 72000    |\n",
            "| value_loss         | 0.00663  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=72231, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.565    |\n",
            "| fps                | 308      |\n",
            "| nupdates           | 14500    |\n",
            "| policy_entropy     | 0.507    |\n",
            "| total_timesteps    | 72500    |\n",
            "| value_loss         | 0.282    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=72731, episode_reward=3.97 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.157    |\n",
            "| fps                | 308      |\n",
            "| nupdates           | 14600    |\n",
            "| policy_entropy     | 0.465    |\n",
            "| total_timesteps    | 73000    |\n",
            "| value_loss         | 0.0272   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=73231, episode_reward=1.77 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.314   |\n",
            "| fps                | 308      |\n",
            "| nupdates           | 14700    |\n",
            "| policy_entropy     | 0.541    |\n",
            "| total_timesteps    | 73500    |\n",
            "| value_loss         | 0.125    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=73731, episode_reward=5.06 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.205   |\n",
            "| fps                | 308      |\n",
            "| nupdates           | 14800    |\n",
            "| policy_entropy     | 0.46     |\n",
            "| total_timesteps    | 74000    |\n",
            "| value_loss         | 1.73     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=74231, episode_reward=3.97 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.536    |\n",
            "| fps                | 308      |\n",
            "| nupdates           | 14900    |\n",
            "| policy_entropy     | 0.303    |\n",
            "| total_timesteps    | 74500    |\n",
            "| value_loss         | 0.455    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=74731, episode_reward=5.56 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| explained_variance | 0.532    |\n",
            "| fps                | 308      |\n",
            "| nupdates           | 15000    |\n",
            "| policy_entropy     | 0.321    |\n",
            "| total_timesteps    | 75000    |\n",
            "| value_loss         | 0.203    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=75231, episode_reward=2.93 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.295    |\n",
            "| fps                | 309      |\n",
            "| nupdates           | 15100    |\n",
            "| policy_entropy     | 0.45     |\n",
            "| total_timesteps    | 75500    |\n",
            "| value_loss         | 0.0956   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=75731, episode_reward=5.07 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.213    |\n",
            "| fps                | 309      |\n",
            "| nupdates           | 15200    |\n",
            "| policy_entropy     | 0.355    |\n",
            "| total_timesteps    | 76000    |\n",
            "| value_loss         | 2.06     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=76231, episode_reward=5.01 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.118    |\n",
            "| fps                | 309      |\n",
            "| nupdates           | 15300    |\n",
            "| policy_entropy     | 0.204    |\n",
            "| total_timesteps    | 76500    |\n",
            "| value_loss         | 0.129    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=76731, episode_reward=1.77 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.476    |\n",
            "| fps                | 309      |\n",
            "| nupdates           | 15400    |\n",
            "| policy_entropy     | 0.125    |\n",
            "| total_timesteps    | 77000    |\n",
            "| value_loss         | 0.203    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=77231, episode_reward=5.07 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.412    |\n",
            "| fps                | 309      |\n",
            "| nupdates           | 15500    |\n",
            "| policy_entropy     | 0.439    |\n",
            "| total_timesteps    | 77500    |\n",
            "| value_loss         | 0.0705   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=77731, episode_reward=4.82 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.7     |\n",
            "| fps                | 309      |\n",
            "| nupdates           | 15600    |\n",
            "| policy_entropy     | 0.379    |\n",
            "| total_timesteps    | 78000    |\n",
            "| value_loss         | 0.0386   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=78231, episode_reward=4.82 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -2.78    |\n",
            "| fps                | 309      |\n",
            "| nupdates           | 15700    |\n",
            "| policy_entropy     | 0.201    |\n",
            "| total_timesteps    | 78500    |\n",
            "| value_loss         | 0.209    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=78731, episode_reward=2.92 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.245   |\n",
            "| fps                | 310      |\n",
            "| nupdates           | 15800    |\n",
            "| policy_entropy     | 0.207    |\n",
            "| total_timesteps    | 79000    |\n",
            "| value_loss         | 22       |\n",
            "---------------------------------\n",
            "Eval num_timesteps=79231, episode_reward=5.02 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.452    |\n",
            "| fps                | 310      |\n",
            "| nupdates           | 15900    |\n",
            "| policy_entropy     | 0.592    |\n",
            "| total_timesteps    | 79500    |\n",
            "| value_loss         | 0.0503   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=79731, episode_reward=2.56 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.516   |\n",
            "| fps                | 310      |\n",
            "| nupdates           | 16000    |\n",
            "| policy_entropy     | 0.0271   |\n",
            "| total_timesteps    | 80000    |\n",
            "| value_loss         | 0.0757   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=80231, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -158     |\n",
            "| fps                | 310      |\n",
            "| nupdates           | 16100    |\n",
            "| policy_entropy     | 0.00524  |\n",
            "| total_timesteps    | 80500    |\n",
            "| value_loss         | 2.84e-05 |\n",
            "---------------------------------\n",
            "Eval num_timesteps=80731, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -293     |\n",
            "| fps                | 310      |\n",
            "| nupdates           | 16200    |\n",
            "| policy_entropy     | 0.00845  |\n",
            "| total_timesteps    | 81000    |\n",
            "| value_loss         | 0.0104   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=81231, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -11.7    |\n",
            "| fps                | 310      |\n",
            "| nupdates           | 16300    |\n",
            "| policy_entropy     | 0.0081   |\n",
            "| total_timesteps    | 81500    |\n",
            "| value_loss         | 0.000515 |\n",
            "---------------------------------\n",
            "Eval num_timesteps=81731, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -48.7    |\n",
            "| fps                | 311      |\n",
            "| nupdates           | 16400    |\n",
            "| policy_entropy     | 0.0106   |\n",
            "| total_timesteps    | 82000    |\n",
            "| value_loss         | 0.000212 |\n",
            "---------------------------------\n",
            "Eval num_timesteps=82231, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -3.8     |\n",
            "| fps                | 311      |\n",
            "| nupdates           | 16500    |\n",
            "| policy_entropy     | 0.0283   |\n",
            "| total_timesteps    | 82500    |\n",
            "| value_loss         | 6.39e-05 |\n",
            "---------------------------------\n",
            "Eval num_timesteps=82731, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -3.16    |\n",
            "| fps                | 311      |\n",
            "| nupdates           | 16600    |\n",
            "| policy_entropy     | 0.0262   |\n",
            "| total_timesteps    | 83000    |\n",
            "| value_loss         | 0.0123   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=83231, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -13.7    |\n",
            "| fps                | 311      |\n",
            "| nupdates           | 16700    |\n",
            "| policy_entropy     | 0.0276   |\n",
            "| total_timesteps    | 83500    |\n",
            "| value_loss         | 4.13e-05 |\n",
            "---------------------------------\n",
            "Eval num_timesteps=83731, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.164   |\n",
            "| fps                | 311      |\n",
            "| nupdates           | 16800    |\n",
            "| policy_entropy     | 0.0603   |\n",
            "| total_timesteps    | 84000    |\n",
            "| value_loss         | 7.72e-05 |\n",
            "---------------------------------\n",
            "Eval num_timesteps=84231, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -1.26    |\n",
            "| fps                | 311      |\n",
            "| nupdates           | 16900    |\n",
            "| policy_entropy     | 0.157    |\n",
            "| total_timesteps    | 84500    |\n",
            "| value_loss         | 7.02e-05 |\n",
            "---------------------------------\n",
            "Eval num_timesteps=84731, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.816   |\n",
            "| fps                | 311      |\n",
            "| nupdates           | 17000    |\n",
            "| policy_entropy     | 0.286    |\n",
            "| total_timesteps    | 85000    |\n",
            "| value_loss         | 0.483    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=85231, episode_reward=4.23 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -2.09    |\n",
            "| fps                | 312      |\n",
            "| nupdates           | 17100    |\n",
            "| policy_entropy     | 0.521    |\n",
            "| total_timesteps    | 85500    |\n",
            "| value_loss         | 0.222    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=85731, episode_reward=1.54 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.15    |\n",
            "| fps                | 312      |\n",
            "| nupdates           | 17200    |\n",
            "| policy_entropy     | 0.68     |\n",
            "| total_timesteps    | 86000    |\n",
            "| value_loss         | 0.161    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=86231, episode_reward=4.04 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.0191   |\n",
            "| fps                | 312      |\n",
            "| nupdates           | 17300    |\n",
            "| policy_entropy     | 0.506    |\n",
            "| total_timesteps    | 86500    |\n",
            "| value_loss         | 0.162    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=86731, episode_reward=1.59 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.5      |\n",
            "| fps                | 312      |\n",
            "| nupdates           | 17400    |\n",
            "| policy_entropy     | 0.515    |\n",
            "| total_timesteps    | 87000    |\n",
            "| value_loss         | 6        |\n",
            "---------------------------------\n",
            "Eval num_timesteps=87231, episode_reward=4.03 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.82     |\n",
            "| fps                | 312      |\n",
            "| nupdates           | 17500    |\n",
            "| policy_entropy     | 0.362    |\n",
            "| total_timesteps    | 87500    |\n",
            "| value_loss         | 0.00739  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=87731, episode_reward=3.42 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.26     |\n",
            "| fps                | 312      |\n",
            "| nupdates           | 17600    |\n",
            "| policy_entropy     | 0.291    |\n",
            "| total_timesteps    | 88000    |\n",
            "| value_loss         | 0.067    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=88231, episode_reward=5.02 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.0758   |\n",
            "| fps                | 312      |\n",
            "| nupdates           | 17700    |\n",
            "| policy_entropy     | 0.28     |\n",
            "| total_timesteps    | 88500    |\n",
            "| value_loss         | 0.891    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=88731, episode_reward=5.02 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.574    |\n",
            "| fps                | 312      |\n",
            "| nupdates           | 17800    |\n",
            "| policy_entropy     | 0.25     |\n",
            "| total_timesteps    | 89000    |\n",
            "| value_loss         | 0.12     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=89231, episode_reward=4.72 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -6.23    |\n",
            "| fps                | 313      |\n",
            "| nupdates           | 17900    |\n",
            "| policy_entropy     | 0.215    |\n",
            "| total_timesteps    | 89500    |\n",
            "| value_loss         | 0.948    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=89731, episode_reward=5.02 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.746    |\n",
            "| fps                | 313      |\n",
            "| nupdates           | 18000    |\n",
            "| policy_entropy     | 0.379    |\n",
            "| total_timesteps    | 90000    |\n",
            "| value_loss         | 0.0199   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=90231, episode_reward=3.97 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.555    |\n",
            "| fps                | 313      |\n",
            "| nupdates           | 18100    |\n",
            "| policy_entropy     | 0.359    |\n",
            "| total_timesteps    | 90500    |\n",
            "| value_loss         | 1.35     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=90731, episode_reward=5.02 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.145   |\n",
            "| fps                | 313      |\n",
            "| nupdates           | 18200    |\n",
            "| policy_entropy     | 0.342    |\n",
            "| total_timesteps    | 91000    |\n",
            "| value_loss         | 0.295    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=91231, episode_reward=2.84 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -23.1    |\n",
            "| fps                | 313      |\n",
            "| nupdates           | 18300    |\n",
            "| policy_entropy     | 0.104    |\n",
            "| total_timesteps    | 91500    |\n",
            "| value_loss         | 3.06     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=91731, episode_reward=3.22 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.0552   |\n",
            "| fps                | 313      |\n",
            "| nupdates           | 18400    |\n",
            "| policy_entropy     | 0.498    |\n",
            "| total_timesteps    | 92000    |\n",
            "| value_loss         | 0.088    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=92231, episode_reward=3.65 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.477    |\n",
            "| fps                | 313      |\n",
            "| nupdates           | 18500    |\n",
            "| policy_entropy     | 0.448    |\n",
            "| total_timesteps    | 92500    |\n",
            "| value_loss         | 0.0176   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=92731, episode_reward=5.02 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.243    |\n",
            "| fps                | 313      |\n",
            "| nupdates           | 18600    |\n",
            "| policy_entropy     | 0.291    |\n",
            "| total_timesteps    | 93000    |\n",
            "| value_loss         | 0.484    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=93231, episode_reward=5.02 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.226    |\n",
            "| fps                | 314      |\n",
            "| nupdates           | 18700    |\n",
            "| policy_entropy     | 0.25     |\n",
            "| total_timesteps    | 93500    |\n",
            "| value_loss         | 6.87     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=93731, episode_reward=4.82 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.0331   |\n",
            "| fps                | 314      |\n",
            "| nupdates           | 18800    |\n",
            "| policy_entropy     | 0.523    |\n",
            "| total_timesteps    | 94000    |\n",
            "| value_loss         | 0.0507   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=94231, episode_reward=4.22 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.555    |\n",
            "| fps                | 314      |\n",
            "| nupdates           | 18900    |\n",
            "| policy_entropy     | 0.322    |\n",
            "| total_timesteps    | 94500    |\n",
            "| value_loss         | 0.0162   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=94731, episode_reward=4.83 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.111    |\n",
            "| fps                | 314      |\n",
            "| nupdates           | 19000    |\n",
            "| policy_entropy     | 0.153    |\n",
            "| total_timesteps    | 95000    |\n",
            "| value_loss         | 1.14     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=95231, episode_reward=3.42 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.175   |\n",
            "| fps                | 314      |\n",
            "| nupdates           | 19100    |\n",
            "| policy_entropy     | 0.2      |\n",
            "| total_timesteps    | 95500    |\n",
            "| value_loss         | 50.7     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=95731, episode_reward=5.02 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.0369   |\n",
            "| fps                | 314      |\n",
            "| nupdates           | 19200    |\n",
            "| policy_entropy     | 0.407    |\n",
            "| total_timesteps    | 96000    |\n",
            "| value_loss         | 0.359    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=96231, episode_reward=2.57 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.177    |\n",
            "| fps                | 314      |\n",
            "| nupdates           | 19300    |\n",
            "| policy_entropy     | 0.334    |\n",
            "| total_timesteps    | 96500    |\n",
            "| value_loss         | 1.45     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=96731, episode_reward=2.93 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.488    |\n",
            "| fps                | 314      |\n",
            "| nupdates           | 19400    |\n",
            "| policy_entropy     | 0.282    |\n",
            "| total_timesteps    | 97000    |\n",
            "| value_loss         | 0.161    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=97231, episode_reward=2.84 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.437    |\n",
            "| fps                | 314      |\n",
            "| nupdates           | 19500    |\n",
            "| policy_entropy     | 0.473    |\n",
            "| total_timesteps    | 97500    |\n",
            "| value_loss         | 24.6     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=97731, episode_reward=1.84 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -14      |\n",
            "| fps                | 314      |\n",
            "| nupdates           | 19600    |\n",
            "| policy_entropy     | 0.477    |\n",
            "| total_timesteps    | 98000    |\n",
            "| value_loss         | 0.104    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=98231, episode_reward=3.42 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.221    |\n",
            "| fps                | 315      |\n",
            "| nupdates           | 19700    |\n",
            "| policy_entropy     | 0.657    |\n",
            "| total_timesteps    | 98500    |\n",
            "| value_loss         | 0.0216   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=98731, episode_reward=1.84 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | -0.118   |\n",
            "| fps                | 315      |\n",
            "| nupdates           | 19800    |\n",
            "| policy_entropy     | 0.37     |\n",
            "| total_timesteps    | 99000    |\n",
            "| value_loss         | 0.154    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=99231, episode_reward=4.22 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.584    |\n",
            "| fps                | 315      |\n",
            "| nupdates           | 19900    |\n",
            "| policy_entropy     | 0.37     |\n",
            "| total_timesteps    | 99500    |\n",
            "| value_loss         | 7.92     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=99731, episode_reward=5.02 +/- 0.00\n",
            "Episode length: 29.00 +/- 0.00\n",
            "---------------------------------\n",
            "| explained_variance | 0.524    |\n",
            "| fps                | 315      |\n",
            "| nupdates           | 20000    |\n",
            "| policy_entropy     | 0.365    |\n",
            "| total_timesteps    | 100000   |\n",
            "| value_loss         | 0.0392   |\n",
            "---------------------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<stable_baselines.a2c.a2c.A2C at 0x7f7cd2b8cb90>"
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Create the RL model\n",
        "\n",
        "model = A2C('MlpLstmPolicy', env, verbose=1) #Using LSTM to keep context\n",
        "model.learn(total_timesteps=100000,callback=[eval_callback])\n",
        "#explained variable : the closer to 1 the better"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTrr5nNhSfhF"
      },
      "source": [
        "**4. Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeGkwMbKf-zn",
        "outputId": "81e04f21-b453-49ed-8d9a-290e04f783ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n"
          ]
        }
      ],
      "source": [
        "#Load saved model\n",
        "model = A2C.load(\"/content/logs/best_model.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8lmVVv7RzZ9",
        "outputId": "79af9963-49e2-4799-c155-ed84ecfec02a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "info {'total_reward': 0.7900000000000063, 'total_profit': 1.019549851639336, 'position': 1}\n"
          ]
        }
      ],
      "source": [
        "env = gym.make('stocks-v0', df=df, frame_bound=(215,235), window_size=5)\n",
        "obs = env.reset()\n",
        "while True: \n",
        "    obs = obs[np.newaxis, ...]\n",
        "    action, _states = model.predict(obs)#Using the trained model to predict next action\n",
        "    obs, rewards, done, info = env.step(action)\n",
        "    if done:\n",
        "        print(\"info\", info)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "6V4-KMs5bjCC",
        "outputId": "2f479f85-0050-4694-d1a9-f096114aa2b5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2cAAAGQCAYAAAAqQxjtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hUZf7+8fuTXgktoYUkNGlShKhgd7EDti3qInaxrLu6u7YV/aqrqKv7W113baxdY1l13RWwFyxYkKIgvYdOaOl9nt8fM4EQEkggyZlJ3q/rypXMOXNm7skMYe55znmOOecEAAAAAPBWmNcBAAAAAACUMwAAAAAICpQzAAAAAAgClDMAAAAACAKUMwAAAAAIApQzAAAAAAgClDMALZ6ZOTPr7XWOA2VmJ5jZOq9zoOHM7Hkzu7cZ7sfM7Dkz22FmM83sWDNb0tT3CwBoXJQzAJ4xs4JqXz4zK652eVwd2zRqUTGz6WZWErjPrWb2HzPr0li37wUzu8fM5ptZhZndtZ/rtjWzF8xsS+Drrhrrh5rZl2aWa2brzOyOGutHmdliMysys8/MLL3aumgze9bM8sxsk5n9obG2PVhm9mS111qZmZVXu/zePrZbbWYnNVKGS8ysMnCfeWb2g5mNOcCbO0bSyZJSnXNHOOe+dM71PZjc+3p+arnuUYFSmG9m88zsmBrrf2tmqwKPc1b19fV4DdZ522Z2W42/I8WBvyUdA+sX1FhfYWZTGvJ7AIDmRDkD4BnnXELVl6RsSWOrLctqxijXBTL0lpQg6a/NeN97MLOIRriZ5ZJuljStHtd9WFKcpAxJR0gab2aXVlv/iqQvJLWXdLyka83szEDWjpL+I+mOwPpZkl6vtu1dkvpISpd0oqSbzey0g922MTjnrq722rtP0uvVXnunN9b91MM3gQxtJT0j6d9m1q7mlerxukiXtNo5V9gYoerx/FS/bntJUyQ9JP/jeFDSlKrHYWZHSnpA0i8kJcn/ON82s/DATdT5GtzfbTvn7qvxd+QvkqY757YG1g+sti5R0lpJbzTG7wgAmgLlDEDQCYyaPGJmGwJfjwSWxUt6T1LXap+EdzWzI8zsGzPbaWYbzeyfZhbV0Pt1zu2U9F9JQ6tl6WdmH5nZdjNbYma/CizvEbi/sMDlf5nZlmrbvWRmNwR+vtTMFgU++V9pZldVu94J5h+RusXMNkl6zsxizb873A4zWyjp8AY+jhecc+9Jyq/H1cdKetA5V+ScWy3/G+fLqq3PkJTlnKt0zq2Q9JWkgYF150pa4Jx7wzlXIn+hGmJm/QLrL5Z0j3Nuh3NukaR/SbqkEbZtUmZ2ZmDEZaf5R1b7B5a/JClN/nJQYGY3B5a/Yf7RvVwz+8LMBu7r9mvjnPNJelZSrKReZnaXmb1pZi+bWZ6kSwKv9XcCr8XlZnZl4P4vl/S0pJGBXHdbtRHmunLvx/6en+qOkrQpcN1K59zLknICtyH5X0MLnHOznXNO0ouSOkpKCazf12twf7e9i5mZpIskvVDHYzoucL9v1ePxA4AnKGcAgtFESSPkL0lD5P80/fbAqMDpkjZU+7R8g6RKSb+X/43XSEmjJF3b0Ds1sw7yv+lbHrgcL+kj+UePUiSdL+lxMxvgnFslKU/SYYHNj5NUUPVGXv5Rps8DP2+RNEZSG0mXSnrYzIZVu+vO8o9OpEuaIOlOSb0CX6fKX1Sq53zczB5v6OPbB6vx86HVLj8i6SIzizSzvvL/fj8OrBso6ceqKwaenxWSBgZGNrpUXx/4eWAjbNuwB+d/017f6x4i6VVJN0hKlvSu/KUmyjk3XnuO8D4Y2Ow9+Uf5UiTNkdTgUd/AyNgVkgokLQssPkvSm/KPGGVJek3SOkld5R+Fus/Mfuace0bS1QqMwjnn7qx+23XlDuwi+Os6ItX5/NT1EGq5XPU6ek9SuJkdGRgtu0zSD5I21bF9zdfgvm67umPlfw7qKl8XS3qrsUYXAaApUM4ABKNxkv7snNvinMuRdLek8XVdOfCJ/LfOuYrAJ+9PyV+O6utRM8uVtFX+gvfbwPIx8u8q9lzgtufK/8bvl4H1n0s63sw6By6/GbjcQ/4i9mMg3zTn3Arn97mkD+V/I1nFJ+lO51ypc65Y0q8kTXLObXfOrZX0aI3He61zrsHlsw7vS7rVzBLNP2nKZfLvYlZlqvxFoFjSYknPOOe+D6xLkJRb4/Zy5d99LKHa5ZrrDnbbPQRGVR8wsxXmP7bqL2Y20Mw6mdkk7fm73p/zJE1zzn3knCuXfxfXWPlHcGrlnHvWOZfvnCvV7hGmpHre3wgz2yl/UblA0jnOuarH/Y1z7r+BUbWOko6WdItzrsQ594P8o2UXNeCx1cw92Dn3Sh2r9/X81PSN/KPZFwRK/MXyf7BQ9TrKl//fzVeSSuX/8GFCYBRN2vdrcH+3Xd3Fkt50zhXUXGFmcfK/jp+v4/ECQFCgnAEIRl0lral2eU1gWa3M7BAzmxrYtSxP/mOIOjbg/n7nnEuSNFhSO0mpgeXpko4M7N62M/Amepz8I12Sv5ydIP+o2ReSpstfCo+X9GXgTbXM7HQz+zawO9pOSWfUyJcT2HWs+uNfW+PxN5XfyV+8lkn6n/yjRlW7w7WX/43znyXFSOou6VQzqyqGBfKX0OrayP9mvKDa5ZrrDnbbmo6UVChpkPzPRZn8pfJrSeWB7/W1x2sv8ByuldSttiubWXi1YpgnaXVgVX1ff98659o65zo650Y45z6utq76a6CrpO3Oueq/gzV15WoE+3p+9uCc2yb/KN8fJG2WdJr8o6tVE/dcLv+I8UBJUZIulDTVzKr+Tdf5GqzHbUvaVb5+qbp3aTxX0nbtHs0GgKBEOQMQjDbIX4yqpAWWSZLb++p6Qv5RnT7OuTaSbtPeu0Ltl3NuvqR7JT0W2BVuraTPA2+eq74SnHPXBDb5XP5RmRMCP38l/+jGrl0azSxa/lGDv0rq5JxrK/+uctXz1XxMG+UvQlXSGvpY6iswOjfOOdfZOTdQ/v8XZgZW95RU6Zx7MTByuE7+XevOCKxfIP9up5J27QbaS/7ji3YEHseu9YGfFzTCtjV95Zy7J3DMUrZz7g7nXA/nXC/n3F3OuYoG/Er2eO0FXgfdJa0PLKr5XP1a/vJwkvyTXWRUbdqA+6xL9fvaIKm9mVUfuUqrlqsht1UfdT4/td64c5875w53zrWXf5S7n3a/joZKmuqcW+qc8znn3pf/+T0qsO2+XoP7u+0q58hfvqbX8XgulvRitdE6AAhKlDMAwehVSbebWbL5Z437P0kvB9ZtltShxm5jifIf/1UQmLDgGh24FyR1knSm/KMvh5jZ+MAuVZFmdnjVcWXOuWXyf+J/ofwlLi+Q7+fa/Ql9lKRo+ScxqDCz0yWdsp8M/5b0JzNrZ2ap2r2bZb0EcsbI/zc+wsxibPfMeDWv28vMOgRGgE6X/5i3qvNyLfVfxX5tZmGB3TfPkzQvsP5tSYea2c8D9/d/kuY55xYH1r8o//PYLvC8XKndu5UdzLZ7qBqhbCT/ljTa/NPIR0r6o/y74lWNvm2Wv7RWSQys3yb/rnb3NWKWXQK7t34t6f7A8zlY/hGpl/e95S41c+/P/p6fPZjZYYHXXRv5P4hY65z7ILD6e/l/pz3N72RJh0j6KbDtvl6D+7vtKnWWr8C/oRNV96gaAAQNyhmAYHSv/FN3z5M0X/5JFu6VpMCbw1clrQzsathV0o3yj2Dkyz+rX61TfteHc65M0t8l3RHYhewU+ScC2SD/cUF/kb9sVflc0rbAm+eqyxbIrMBt/E7+N/07Ajnf2U+Mu+XfZW2V/MenvVR9pfnP0fXkPrb/l/yl8QL5J1cpVuCYPfOfnLj6MTnD5f8d50u6X9I459yCQPY8+XcH+30g+w/yv6Guei5y5C+ikwLrj5T/d1XlTvknkVgT+L08FBg1Oahtm5Jzbon8Zfsf8h+DOFb+iTTKAle5X/7SuNPMbpS/RK6RfwRroaRvmzDeBfKPzG2QvzzdWWM3yH2pmbvqHGC1nk9wf89PLa/Bm+X/fa2VfzKXc6qte1H+Edfp8n+I8qikq6oVvTpfg/W4bZlZN0k/C9xPbcbLf/zeijrWA0DQMEb4AQAAAMB7jJwBAAAAQBCgnAEAAABAEKCcAQAAAEAQoJwBAAAAQBCgnAEAAABAEKCcAQAAAEAQoJwBAAAAQBCgnAEAAABAEKCcAQAAAEAQoJwBAAAAQBCgnAEAAABAEKCcAQAAAEAQoJwBAAAAQBCgnAEAAABAEKCcAQAAAEAQoJwBAAAAQBCgnAEAAABAEKCcAQAAAEAQoJwBAAAAQBCgnAEAAABAEKCcAQAAAEAQoJwBAAAAQBCgnAEAAABAEKCcAQAAAEAQoJwBAAAAQBCgnAEAAABAEKCcAQAAAEAQoJwBAAAAQBCgnAEAAABAEKCcAQAAAEAQoJwBAAAAQBCgnAEAAABAEIhozjvr2LGjy8jIaM67BAAAAICgMXv27K3OueTa1jVrOcvIyNCsWbOa8y4BAAAAIGiY2Zq61rFbIwAAAAAEAcoZAAAAAAQByhkAAAAABAHKGQAAAAAEAcoZAAAAAAQByhkAAAAABAHKGQAAAAAEAcoZAAAAAAQByhkAAAAABAHKGQAAAA5eVpaUkSGFhfm/Z2V5nQgIORFeBwAAAECIy8qSJkyQior8l9es8V+WpHHjvMsFhBhGzgAAAHBAnHMqKK1Qxa1/2l3MqhQVSRMnehMMCFGMnAEAALRyzjnll1Yot6hcO4rKtLOoXDuLy5Vb7eedReXKLfZf3lFUptzAsgqf08p162q/4ezs5n0gQIijnAEAADSjrPlZmvjJRGXnZistKU2TRk3SuEGNs+tfpc8pv6S8WqHaXaKqSlduYLm/fAVKWHG5Kn2uztuNjwpX27gotY2LVNu4SPXr3EZJcZFqG+u/XPxCV8VvWr/XdjntUjT7p006eUAnhYdZozxGoCWjnAEAADSTrPlZmjBlgorK/bsArsldowlT/MdmVS9oFZU+5ZVUVCtUgRGs6iNaxXuWsJ1F5corKZeru2MpMSbCX7Bi/UWrW9tYtY2LVLu4KCXFRvoLWKBwtY2LVFKsf3lUxH6OhPnrX/Y85kxSeXSsHjvpMj3/8myltovVJUdl6FeHd1ebmMgD/wUCLZy5ff0LbmSZmZlu1qxZzXZ/AAAAwSTjkQytyV2z1/L48M46MekN7QyUsPySijpvw0xqExOpdnGRSqpepmJrXI6rXrai1CYmQhHhTTjdQFaW/xiz7GwpLU2aNEkV51+gjxdt1rNfrdbM1duVEB2hX2am6pKjMpTeIb7psgBBzMxmO+cya11HOQMAAGha2duKNHX+Bv3m80Mk1fbey3RJ2rdqGxjBaldtF8KaI1qJMZEhuYvg/HW5enbGKk35cYMqndNJ/Tvp8mN66Mge7WUWeo8HOFCUMwAAgGa2YWexps3bqKnzNujHdbmSpC3xl6vYt3mv66YnpWv1DaubOaE3NueV6KVv1ijruzXaUVSuAV3a6LJjemjskC6Kjgj3Oh7Q5ChnAAAAzWBzXsmuQjYne6ckaVC3JI0e3EWjB3XRF+vf3uOYM0mKi4zT5LGTG21SkFBRUl6p/85dr2dnrNLSzQXqmBCt8SPSNW5EmjomRHsdD2gylDMAAIAmsrWgVO/N36gp8zbq+9Xb5ZzUr3Oixg7pqtGDuiij457HVjXlbI2hyDmnGcu36ZmvVuqzJTmKCg/TWUO76rJjeqh/lzZexwMaHeUMAACgEe0oLNP7CzZp6rwN+mbFNvmc1DslQWMGd9GYwV3VOyXB64ghaUVOgZ6fsVpvzl6n4vJKHdWrgy47uod+1i9FYSF4nB1QG8oZAADAQcotLteHCzZp6ryNmrF8qyp8Thkd4jRmcFeNGdJFfTslMrFFI8ktKter32frha9Xa2NuiTI6xOnSo3voF8NTFR/NmaAQ2ihnAAAAByC/pFwfL9qsqT9u1BfLclRe6ZTaLtZfyAZ30cCubShkTai80qcPFmzSM1+t0tzsnUqMidD5h3fXRSMz1L19nNfxgANCOQMAAKinorIKfbJoi6bO26DPluSorMKnLkkxGj2oi8YM6aohqUkUMg/Myd6h52as1rvzN8o5p1MHdtblx/TQ8PR2PB8IKZQzAACAfSgpr9T0JVs0Zd5Gfbpoi4rLK5WcGO0vZIO7aFhaO455ChIbdhbrxW/W6NWZ2cotLtfg1CRdfkwPnX5oF0VFNOFJtoFGQjkDAACoobSiUl8u3aqp8zboo4WbVVhWqQ7xUTp9UGeNHtRVR/RoH5Ine24tisoq9J85/qn4V+YUqlObaF00MkMXHJGm9vFRXscD6kQ5AwAAkP8Ypq+Wb9XUHzfqw4WblF9SobZxkTptYGeNGdxVI3q2V0Q4oy+hxOdz+mJZjp75apW+XLZV0RFhOndYN112dA/16ZTodTxgL/sqZ0x3AwAAWrSKSp++XbldU+dt0PsLNmlnUbkSYyJ0yoDOGjOki47p3VGRFLKQFRZmOqFvik7om6Klm/P13IzV+s+cdXp15lod26ejLj+mh47rk8xuqQgJjJwBAIAWp9Ln9P3qQCH7aZO2FpQpPipcJw3opDGDu+q4QzoqOiLc65hoItsLy/TqTP9U/FvyS9UrOV6XHt1D5w7rprgoxibgLXZrBAAALZ7P5zR37Q5N+XGj3p2/UVvySxUTGaZR/Ttp7OAuOqFvimIiKWStSVmFT+/9tFHPfLVK89blKik2UhcckaaLj0pXl6RYr+OhlaKcAQCAFsk5px/X5Wrqjxv07vyN2pBboqiIMJ3YN1ljBnfVqP4pjJRAzjnNXrNDz85Ypfd/2iQz0xmDuuiyozN0WFo7r+OhleGYMwAA0GI457RgQ56mztuoafM3aO32YkWGm47rk6ybTuurk/p3UmJMpNcxEUTMTJkZ7ZWZ0V7rdhTtmop/yo8bNCytrS47podOG9iZyWDgOUbOAABA0Mman6WJn0xUdm620pLSNGnUJGUmn6mp8zZo6ryNWrW1UBFhpqN7d9SYwV10ysDOSoqlkKH+Ckor9NbsdXpuxiqt3lakrkkxuuioDF1weJqS4ngtoemwWyMAAAgZWfOzNGHKBBWVF+1aFqZotSu7Tm18J2pkrw4aM7irThvYWe04nxUOks/n9OniLXp2xip9vWKbYiPD9Yvhqbrk6Az1Sk6o9YOCcYPGeR0bIYxyBgAAQkbGIxlak7tmr+UdYrpp0bUrlJwY7UEqtAaLNubpuRmr9N8fNqiswqe0brM1M/cBlVYW77pOXGScJo+dTEHDAaOcAQCAkBF2d5ic9n5/YjL57vR5kAitzdaCUmV9m62bZxyjMm3Za31aUprW3LD3BwhAfTAhCAAACBmd47tpY+G6vZanJaV5kAatUceEaF1/Uh/9fkZOreuzd67Vmf/8Sr2SE9QrOd7/PSVB6R3iOH8eDgrlDAAABI2c/FLFFY9XmP4mn0p3LY+LjNOkUZM8TIbWKC0prdZdbJOi/BPQzFy1XW/PXb9reZhJ3dvH7VXaenaMV/v4KJlZc8ZHCKpXOTOz1ZLyJVVKqnDOZZrZQ5LGSiqTtELSpc65nU0VFAAAtGzllT5d98ocRZQdq/tP7qnH59zLJAzw1KRRk/aanCYuMk6PjX1I4wYdKUkqKqvQypxCrcgp0IqcQq0MfJ+xfKtKK3bvhts2LnLP0pacoJ7J8UprH8cU/tilXsecBcpZpnNua7Vlp0j61DlXYWZ/kSTn3C37uh2OOQMAAHX585SFenbGKj1y3lCdfVg3r+MAkmo/rUN9Pijw+ZzW7yzWipyCauXNX9xy8nePCkeGm9I7xO9V2nqlJKgN5+s7IME+w+ZBTwhSWzmrsf4cSb9wzu3zUVPOAABAbf73w3pd/9oPuvToDN05dqDXcYAmlVtcvmuEbWW10rZ6a6EqfLvfmycnRu9d2pIT1K1trMLC2EWyNrWdiiPYZthsjHK2StIOSU7SU865yTXWT5H0unPu5X3dDuUMAADUtHBDns59YoYGp7ZV1hVHKpJdvNBKlVf6tHZ70V6lbfmWAuUWl++6XkxkmHp03L2LZM9q3+OiQntKiZLyShWUVii/pEIFJRXKLylX/q7L5f7vpRXKC3zPLykPXM9/+fuSC1Rue8+wmZ6UrtU3rG7+B1SLxpit8Rjn3HozS5H0kZktds59EbjxiZIqJGXVcecTJE2QpLQ0ZlkCAAC77Swq01Uvz1JSbKQe+/UwihlatcjwMPVMTlDP5ARJnXYtd85pe2HZXqVt/vpcvTt/o6oNtqlb29hdZa36pCQpidF7TUjSmLv/VVT6dpWq/OrFqapIley+XHWdqsvVy1hZ5f5PlxETGaaE6Ei1iYlQQkyEEmMi1CEhTokxkfp6YR0zbOZmH9Djam4NPs+Zmd0lqcA591czu0TSVZJGOeeK9rmhGDkDAAC7VfqcLn3+e32zYqtev2qkhqW18zoSEHJKyiu1ZlvRHqVtRU6BVmwpUGFZ5a7rJURH7DHSll38of7xw00qqdh9gu2YiFjdftQjOqbbOXuUqVrLVY1Rq+Lyytri7SE8zJQYKFMJ0ZH+n6MDl2MilBgTqYToiN2lKzpyV/lKDFw/PjpCURF1f4hT10nsW8zImZnFSwpzzuUHfj5F0p/N7DRJN0s6vj7FDAAAoLqHP1qqL5bm6L5zBlHMgAMUExmuvp0T1bdz4h7LnXPanFe6V2n7duU2/Wfueq2LvluVYcV7bFNSUaw7p9+u1NK9J+RJjN49SpUQHaG2sZFKbRfrL1LRu4tVzfJVvVzFRIY1+ekE6pphM1ROxVGf3Ro7SXo78IuMkPSKc+59M1suKVr+3Rwl6Vvn3NVNlhQAALQYHyzYpH9+tlznH95dvz6Swx6AxmZm6pwUo85JMTqqd8c91hWWVijxgVrn+ZMvbKveumbkHmUrPioiZCYgqdotM5hna9yXBu/WeDDYrREAACzfUqCzH5uhXsnxev2qkYqJDPc6EtDqhMLufy3VvnZr5KhbAADQbPJLynXVS7MUHRGmJy4cTjEDPDJp1CTFRcbtsSyUdv9rqShnAACgWTjndOMbP2r1tiL989fD1LVtrNeRgFZr3KBxmjx2stKT0mUypSelB9W5wFqr0D4RAgAACBmPT1+hDxZs1u2j+2tkrw5exwFavXGDxlHGggwjZwAAoMl9sTRHf/1wicYO6arLj+nhdRwACEqUMwAA0KTWbi/Sb1+dq76dEvWXnw9q8qm0ASBUUc4AAECTKS6r1FUvzZZzTk+NH664KI6oAIC68BcSAAA0Ceecbnt7vhZtytOzlxyu9A7xXkcCgKDGyBkAAGgSz3+9Wm/PXa8/nHSITuyb4nUcAAh6lDMAANDovlu5TZOmLdJJ/TvpNyf29joOAIQEyhkAAGhUm3JL9JtX5iitfZz+dt4QhYUxAQgA1AfHnAEAgEZTWlGpa7Jmq7isUq9eOUJtYiK9jgQAIYNyBgAAGs3dUxZqbvZOPTFumPp0SvQ6DgCEFHZrBAAAjeL177P1ynfZuuaEXjp9UBev4wBAyKGcAQCAg/bD2p26478LdGyfjrrxlL5exwGAkEQ5AwAAB2VrQamueXm2khOj9ej5hymcCUAA4IBwzBkAADhgFZU+XffKHG0vLNNb1xyldvFRXkcCgJBFOQMAAAfsgfcW69uV2/W3Xw3Rod2SvI4DACGN3RoBAMAB+d8P6/X0V6t08ch0nTss1es4ABDyKGcAAKDBFm3M0y1vzdPhGe10+5gBXscBgBaBcgYAABokt6hcV700W21iIvXYuGGKDOftBAA0Bo45AwAA9ebzOV3/+lxtzC3WaxNGKiUxxutIANBi8FEXAACot0c+XqrpS3J059iBGp7ezus4ANCiUM4AAEC9fLRwsx79dLl+OTxV445M8zoOALQ4lDMAALBfK3IK9IfXf9Dg1CTdc/ahMuNE0wDQ2ChnAABgnwpKK3TVS7MVGRGmJy4crpjIcK8jAUCLRDkDAAB1cs7ppjd+1MqcAv3zgsPUrW2s15EAoMWinAEAgDo9+flKvffTJv3p9P46qndHr+MAQItGOQMAALX6clmOHvpgscYM7qIrju3hdRwAaPEoZwAAYC9rtxfpt6/OVZ+URD34i8FMAAIAzYByBgAA9lBSXqmrX56tSp/TU+OHKy4qwutIANAq8NcWAADs4pzTbf+Zr4Ub8/TMxZnK6BjvdSQAaDUYOQMAALu8+M0a/Wfuet0w6hD9rF8nr+MAQKtCOQMAAJKk71dv1z1TF+qk/in67c96ex0HAFodyhkAANDmvBJdmzVH3dvH6W/nDVVYGBOAAEBz45gzAABaubIKn655ebYKSyuUdcWRahMT6XUkAGiVKGcAALRyf566QHOyd+qxXw/TIZ0SvY4DAK0WuzUCANCK/XvWWr38bbauOq6nRg/u4nUcAGjVKGcAALRS89bt1O3//UlH9+6gm07t63UcAGj1KGcAALRC2wpKdfVLs5WcEK1/XDBMEeG8JQAAr3HMGQAArUxFpU+/fXWuthaW6a2rj1L7+CivIwEAxMgZAACtzoMfLNHXK7bpvnMGaVBqktdxAAABlDMAAFqRKT9u0OQvVmr8iHT9Yniq13EAANVQzgAAaCWWbMrXzW/O0/D0drpjzACv4wAAaqjXMWdmtlpSvqRKSRXOuUwzay/pdUkZklZL+pVzbkfTxAQAAAcjt7hcV700SwkxEXp83DBFRfD5LAAEm4b8ZT7ROTfUOZcZuHyrpE+cc30kfRK4DAAAgozP5/T713/Quh3FemLcMHVqE+N1JABALQ7mY7OzJL0Q+PkFSWcffBwAANDY/v7JMn26eIvuHDtAmRntvY4DAKhDfcuZk/Shmc02swmBZZ2ccxsDP2+S1Km2Dc1sgpnNMrNZOTk5BxkXAAA0xCeLNuvvnyzTz4el6sIR6V7HAQDsQ33Pc3aMc269maVI+sjMFldf6ZxzZuZq29A5N1nSZEnKzMys9ToAAKDxrdpaqBte/0GHdmujSeccKjPzOhIAYB/qNXLmnFsf+L5F0tuSjpC02cy6SFLg+5amCgkAAIStcgYAACAASURBVBqmsLRCE16cpYgw05MXDldMZLjXkQAA+7HfcmZm8WaWWPWzpFMk/STpHUkXB652saT/NVVIAABQf8453fzmPK3IKdA/Lhim1HZxXkcCANRDfUbOOkn6ysx+lDRT0jTn3PuSHpB0spktk3RS4DIAAEEna36WMh7JUNjdYcp4JENZ87O8jtSkJn+xUtPmb9TNp/XTMX06eh0HAFBP+z3mzDm3UtKQWpZvkzSqKUIBANBYsuZnacKUCSoqL5IkrcldowlT/HNbjRs0zstoTWLG8q36y/uLNXpQF111XE+v4wAAGqC+E4IAABCSJn4ycVcxq1JUXqSr/nejZi8cqDaxkWoTG6mkfXzFRIaFxGQa63YU6bpX5qhXcoIe/MXgkMgMANiNcgYAaNGyc7NrXV5YuVkzV29XbnG58ksq9nkbUeFhgQIXUWeRq7m86nJ8VHjTlqSsLGniRLnsbEW1TdEpJ1ysq566Q/HR/BcPAKGGv9wAgBZpzbZC3TN1kcJ8HVUZtvd5NtOT0vTVDT+TJFX6nPJLypVbXPtXXnFF4Lv/8raCMq3MKfQvKymX28eJYiLCbFdR27PARfiXxdRR8uIilRAVobCwfRS7rCxpwgSpqEgmKWXHZt333j8U/uFgaVzL22UTAFo6yhkAoEUpKqvQ45+t0OQvVyoizDR+4J/07+W3q6hi966NcZFxmjRq0q7L4WGmtnFRahsX1eD78/mc8ksrdhW3vDoK3q6vojJlbytUXom/8FX66m52YabdxS5m7wL3mz/erMSiPXfZDC8pliZOpJwBQAiinAEAWgTnnKbN36j7pi3ShtwSnT20q/50Rn91anOaTpqfoomfTFR2brbSktI0adSkRpsMJCzMdpWm7geQubCsMlDaqo/U1Ri5qzaqtyG3eNf6mzdvrP2Gs2vflRMAENzM7WtfjEaWmZnpZs2a1Wz3BwBoHZZsytdd7yzQNyu3aUCXNrr7rIE6PKO917GalHNOLiNDYbUVsfR0afXqZs8EANg/M5vtnMusbR0jZwCAkJVbXK6HP1qql75do8SYCN1z9qH69RFpCt/XcVothJnJ7rtv1zFnu8TFSZMm1b0hACBoUc4AACHH53P696y1evCDJdpZVKZfH5mmP57cV+3iG37MWEirOq5s4kT/roxpaf5ixvFmABCSKGcAgJAyN3uH7nxngeaty1VmejvddeYROrRbktexvDNuHGUMAFoIyhkAICTk5JfqL+8v1puz1yklMVqPnDdUZw3tyomWAQAtBuUMABDUyit9euHr1fr7x8tUUlGpq47vqd/+rI8SOMkyAKCF4X82AEDQmrF8q+56Z4GWbSnQ8Yck6//GDlCv5ASvYwEA0CQoZwCAoLNuR5HunbpI7y/YpLT2cfrXRZk6qX8KuzACAFo0yhkAIGiUlFfqyc9X6InpK2Qm3XjKIbri2J6KiQz3OhoAAE2OcgYA8JxzTh8s2Kx7py3Uuh3FGj24iyae0V9d28Z6HQ0AgGZDOQMAeGr5lgLdPWWBvly2VX07JeqVK4/UUb06eh0LAIBmRzkDAHgiv6Rcj36yTM/NWK3YqHDdOXaAxo9IV0R4mNfRAADwBOUMANCsfD6nt+eu1wPvL9bWglL9anh33XRaX3VMiPY6GgAAnqKcAQCazfx1ubrznZ80J3unhnRvq6cvytSQ7m29jgUAQFCgnAEAmtz2wjI99MFivfb9WnWIj9JDvxisnw9LVVgYU+MDAFCFcgYAaDIVlT5lfZet//fhEhWWVeqyo3vo+pP6qE1MpNfRAAAIOpQzAECT+HblNt31zgIt3pSvo3t30F1jB6pPp0SvYwEAELQoZwCARrUxt1j3vbtYU37coG5tY/XEuGE67dDOMmMXRgAA9oVyBgBoFKUVlXr6y1X656fLVemcfjeqj645vpdio8K9jgYAQEignAEADtonizbrz1MXas22Ip0yoJPuGDNA3dvHeR0LAICQQjkDABywVVsL9ecpC/TZkhz1So7Xi5cdoeMOSfY6FgAAISnM6wAAEJKysqSMDCkszP89K8vrRM2qsLRCf3l/sU59+At9v3qHJp7RX+9dfxzFDACAg8DIGQA0VFaWNGGCVFTkv7xmjf+yJI0b512uZuCc0zs/btD97y7WprwSnTusm249rZ9S2sR4HQ0AgJBHOQOAhpo4cXcxq1JUpLJbbtWGU89WUmyk2sRGKryFnWB54YY83TVlgWau2q5Du7XRY+MO0/D09l7HAgCgxaCcAUBDZWfXujhi/Xqd8Nfpuy4nRkeoTWykkmp8tYmNqPZzbesjFRkePHud7ywq0//7cKmyvlujpNhI3X/uIP0qs3uLK58AAHiNcgYADeS6d5fVUtBKu3TT//vlEOUWl+/6yqv6XlKulVsLdi0vKfft8z7io8J3FbfaClzNklf9etERBz51fdb8LE38ZKKyc7PVPam7Rqf/Qd/M76/c4nKNH5GuP5zcV0lxkQd8+wAAoG6UMwBooFkTbtLAu25UXEXp7oVxcYp96AH9fHhqvW6jtKJyj/Lm/7lij2JX/Wvt9iL9FLh+YVnlPm87JjJsd2GL2bu87fEVt/s67618Q9e9d7WKyv27bGbnZuvJH2/R4Um3atqVf1D/Lm0O+HcGAAD2j3IGAA1QXFap34X1189/fbP+OP0F2dq1UlqaNGlSgyYDiY4IV0piuFISGz6RRnmlb49St/coXYVyi3Yv35hbosWb8pVXXK780oo6b3dd9B9VGbbnsXTOSrXJnlP/Lnc1OCcAAGgYyhkANMC/vlypjbklOu6uG2Q9/uxJhsjwMHVIiFaHhOgGb1tR6VN+SYXySvYudxe+v7XWbdbmrj3YyAAAoB4oZwBQT5vzSvTE9BU6Y1BnHdEjNGcpjAgPU7v4KLWLj9pr3cRv0rQmd81ey9OS0pojGgAArV7wTAcGAEHuoQ+WqNLndOtp/b2O0iQmjZqkuMi4PZbFRcZp0qhJHiUCAKB1oZwBQD38tD5Xb81Zp0uPzlBah7j9bxCCxg0ap8ljJys9KV0mU3pSuiaPnaxxg1r2ibUBAAgW7NYIAPvhnNM9UxeqfVyUfvOz3l7HaVLjBo2jjAEA4BFGzgBgPz5YsFnfrdqu3598iNrEcI4vAADQNChnALAPpRWVuv+9RTqkU4LOP7y713EAAEALRjkDgH148es1WrOtSBNHD1BEOH8yAQBA0+GdBgDUYXthmR79dJlO6Jus4w9J9joOAABo4epdzsws3MzmmtnUwOVRZjbHzH4ws6/MrGUfJQ+g1Xnk46UqKqvU7aNb5tT5AAAguDRk5Ox6SYuqXX5C0jjn3FBJr0i6vTGDAYCXlm3OV9Z32Rp3ZJp6pyR6HQcAALQC9SpnZpYqabSkp6stdpLaBH5OkrShcaMBgHcmvbtIcVHhuuGkQ7yOAgAAWon6nufsEUk3S6r+8fEVkt41s2JJeZJG1LahmU2QNEGS0tLSDjwpADSTz5fmaPqSHE08o7/ax0d5HQcAALQS+x05M7MxkrY452bXWPV7SWc451IlPSfpb7Vt75yb7JzLdM5lJidzQD2A4FZR6dOkaQuV3iFOFx2V7nUcAADQitRn5OxoSWea2RmSYiS1MbNpkvo5574LXOd1Se83UUYAaDavfb9WSzcX6MkLhys6ItzrOAAAoBXZ78iZc+5PzrlU51yGpPMlfSrpLElJZlZ1MMbJ2nOyEAAIOXkl5Xr4o6U6skd7nTqwk9dxAABAK1PfY8724JyrMLMrJb1lZj5JOyRd1qjJAKCZPfbpcm0vKtMdYwbIzLyOAwAAWpkGlTPn3HRJ0wM/vy3p7caPBADNL3tbkZ6bsVo/H5aqQ7sleR0HAAC0Qg05zxkAtFgPvL9IEeGmm07t63UUAADQSlHOALR6M1dt17vzN+nq43upU5sYr+MAAIBWinIGoFXz+ZzumbpQXZJidOWxPb2OAwAAWjHKGYBW7e256zV/fa5uPq2vYqOYOh8AAHiHcgag1Soqq9BDHyzRkNQknTWkm9dxAABAK0c5A9BqTf5ipTblleiOMQMUFsbU+QAAwFuUMwCt0qbcEj31+UqNHtxFmRntvY4DAABAOQPQOj34wWJV+pxuPa2f11EAAAAkUc4AtELz1u3Uf+as12XH9FD39nFexwEAAJBEOQPQyjjndO/UReqYEKXfnNjL6zgAAAC7UM4AtCrv/7RJM1dv1x9O7qvEmEiv4wAAAOxCOQPQapRWVOr+9xarX+dEnXd4d6/jAAAA7IFyBqDVeH7GamVvL9LE0f0VztT5AAAgyFDOALQKWwtK9c9Pl+tn/VJ0bJ9kr+MAAADshXIGoFV45OOlKi6v1G1n9Pc6CgAAQK0oZwBavKWb8/XKd9m6cES6eqckeB0HAACgVpQzAC3evdMWKSE6QteP6uN1FAAAgDpRzgC0aJ8t2aIvlubod6P6qF18lNdxAAAA6kQ5A9BilVf6NGnaIvXoGK+LRmZ4HQcAAGCfKGcAWqzXZmZr+ZYC/en0foqK4M8dAAAIbrxbAdAi5RaX628fLdXInh108oBOXscBAADYL8oZgBbpn58u087ict0+pr/MOOE0AAAIfpQzAC3O6q2Fev7r1frl8FQN7JrkdRwAAIB6oZwBaHHuf2+RIsPDdOMpfb2OAgAAUG+UMwAtyrcrt+mDBZt17Qm9lNImxus4AAAA9UY5A9Bi+HxO905bqK5JMbri2J5exwEAAGgQyhmAFuOtOev00/o83XJ6P8VEhnsdBwAAoEEoZwBahMLSCj30wRIN7d5WZw7p6nUcAACABqOcAWgRnvpipbbkl+qOMQOYOh8AAIQkyhmAkLcxt1iTv1ihsUO6anh6O6/jAAAAHBDKGYCQ9+D7S+Rz0i2nMXU+AAAIXZQzACHth7U79fbc9brimB5KbRfndRwAAIADRjkDELKcc7p36kJ1TIjWtSf29joOAADAQaGcAQhZ787fpFlrdujGUw5RQnSE13EAAAAOCuUMQEgqKa/U/e8tUr/OifplZnev4wAAABw0yhmAkPTcjNVat6NYd4wZoPAwps4HAAChj3IGIOTk5Jfqsc+W66T+KTq6d0ev4wAAADQKyhmAkPO3j5aqpLxSt53R3+soAAAAjYZyBiCkLN6Up9e/z9b4kenqmZzgdRwAAIBGQzkDEDKcc5o0bZESYyJ1/ag+XscBAABoVJQzACHjsyVb9OWyrbp+VB+1jYvyOg4AAECjopwBCAnllT7dO22RenaM1/iR6V7HAQAAaHT1LmdmFm5mc81sauCymdkkM1tqZovM7HdNFxNAa5f17RqtzCnUbWf0V2Q4nysBAICWJ6IB171e0iJJbQKXL5HUXVI/55zPzFIaORsASJJyi8r1yCfLdFSvDhrVnz81AACgZarXx89mlipptKSnqy2+RtKfnXM+SXLObWn8eAAgPfrpMuUWl+v20QNkxgmnAQBAy1TffYMekXSzJF+1Zb0knWdms8zsPTOrdeo0M5sQuM6snJycg4wLoLVZtbVQL36zWudldteArm32e30AAIBQtd9yZmZjJG1xzs2usSpaUolzLlPSvyQ9W9v2zrnJzrlM51xmcnLyQQcG0Lrc9+4iRYWH6Q+nHOJ1FAAAgCZVn2POjpZ0ppmdISlGUhsze1nSOkn/CVznbUnPNU1EAK3V1yu26qOFm3XTqX2VkhjjdRwAAIAmtd+RM+fcn5xzqc65DEnnS/rUOXehpP9KOjFwteMlLW2ylABanUqf071TF6lb21hdfkwPr+MAAAA0uYbM1ljTA5KyzOz3kgokXdE4kQBAemv2Oi3cmKdHLzhMMZHhXscBAABocg0qZ8656ZKmB37eKf8MjgDQqApKK/TQh0s0LK2txg7u4nUcAACAZsGZXAEEnSenr1BOfqluH8PU+QAAoPWgnAEIKut3FutfX67UmUO6alhaO6/jAAAANBvKGYCg8uD7iyVJt5zez+MkAAAAzYtyBiBozM3eof/9sEFXHttT3drGeh0HAACgWVHOAAQF55zumbpQyYnRuuaEXl7HAQAAaHaUMwBBYcq8jZqTvVM3ndJX8dEHc5YPAACA0EQ5A+C5kvJK/eW9xRrQpY1+PjzV6zgAAACeoJwB8NwzX63S+p3Fun1Mf4WHMXU+AABonShnADy1Jb9Ej3+2XCcP6KSjenX0Og4AAIBnKGcAPPW3D5eqtMKn287o73UUAAAAT1HOAHhm4YY8vT5rrS4amaEeHeO9jgMAAOApyhkATzjndO+0hUqKjdT1o/p4HQcAAMBzlDMAnvhk0RZ9vWKbbhjVR0lxkV7HAQAA8BzlDECzK6vw6b53F6lXcrzGjUj3Og4AAEBQoJwBaHYvf7tGK7cWauLo/ooM588QAACARDkD0Mx2FpXp758s0zG9O+rEvilexwEAAAgalDMAzervnyxTfkm5bh/TX2accBoAAKAK5QxAs1mRU6CXvlmj8w5PU7/ObbyOAwAAEFQoZwCazf3vLlJMZLj+cPIhXkcBAAAIOpQzAM1ixvKt+njRFl17Yi8lJ0Z7HQcAACDoUM4ANLlKn9M9UxcqtV2sLju6h9dxAAAAghLlDECTe2PWWi3elK9bT++nmMhwr+MAAAAEJcoZgCaVX1Kuv364VJnp7TR6UBev4wAAAAQtyhmAJpNXUq7Ln5+lbYWlun3MAKbOBwAA2IcIrwMAaJm2FZTq4udmavHGfP39/MM0tHtbryMBAAAENcoZgEa3YWexxj/zndbtKNa/LsrUif1SvI4EAAAQ9ChnABrVqq2FuvDp75RXXK6XLj9SR/Ro73UkAACAkEA5A9BoFmzI1cXPzpTPSa9OGKFDuyV5HQkAACBkUM4ANIpZq7fr0ue/V0J0hF66/Ej1TknwOhIAAEBIoZwBOGjTl2zR1S/PVpekWL10+RFKbRfndSQAAICQQzkDcFCmzduoG16fqz4piXrx8iPUMSHa60gAAAAhiXIG4IC9NjNbt709X8PS2umZSw5XUmyk15EAAABCFuUMwAGZ/MUK3ffuYh1/SLKevHC4YqPCvY4EAAAQ0ihnABrEOae/frhEj322QqMHddHD5w1VVESY17EAAABCHuUMQL35fE7/985PevnbbF1wRHfde/YghYeZ17EAAABaBMoZgHopr/Tpxjd+1P9+2KCrju+pW0/rJzOKGQAAQGOhnAHYr5LySv0ma44+WbxFN5/WV9ee0NvrSAAAAC0O5QzAPuWXlOuKF2Zp5urtuufsQzV+RLrXkQAAAFokyhmAOm0rKNUlz32vRRvz9Mh5Q3XW0G5eRwIAAGixKGcAarUxt1gXPv2d1u0o1uSLhutn/Tp5HQkAAKBFo5wB2MuqrYW68OnvlFtcrhcvO0JH9uzgdSQAAIAWj3IGYA8LN+TpomdnyuecXr1yhAalJnkdCQAAoFWo95ljzSzczOaa2dQayx81s4LGjwaguc1es13nT/5GkeGmf181kmIGAADQjOpdziRdL2lR9QVmlimpXaMmAuCJL5bm6MKnZ6pDQrTeuHqkeqckeB0JAACgValXOTOzVEmjJT1dbVm4pIck3dw00QA0l3fnb9TlL3yvjI7x+vdVI5XaLs7rSAAAAK1OfUfOHpG/hPmqLbtO0jvOuY2NngpAs3n9+2xd98ocDUltq9cmjFByYrTXkQAAAFql/ZYzMxsjaYtzbna1ZV0l/VLSP+qx/QQzm2Vms3Jycg4qLIDG9a8vVuqWt+brmD7JevHyI5QUG+l1JAAAgFarPrM1Hi3pTDM7Q1KMpDaSFkgqlbTczCQpzsyWO+d619zYOTdZ0mRJyszMdI0VHMCBc87p/324VP/8bLlGD+qih88bqqiIhhyCCgAAgMa233djzrk/OedSnXMZks6X9Klzrp1zrrNzLiOwvKi2YgYg+Ph8Tne+s0D//Gy5zj+8ux694DCKGQAAQBDgPGdAK1Je6dPNb87T23PX66rjeurW0/spMPoNAAAAjzWonDnnpkuaXsty5twGglxJeaWue2WOPl60RTed2lfXntCLYgYAABBEGDkDWoH8knJd8cIszVy9XfecfajGj0j3OhIAAABqoJwBLdz2wjJd8txMLdiQp0fOG6qzhnbzOhIAAABqQTkDWrBNuSW68JnvtHZ7kSaPH65R/Tt5HQkAAAB1oJwBLdTqrYW68JnvtLOoXC9cdoRG9OzgdSQAAADsA+UMaIEWbczT+GdmqtLn06tXjtCg1CSvIwEAAGA/KGdACzN7zQ5d+txMxUVF6LUJI9U7JdHrSAAAAKgHyhnQgny5LEcTXpytTm2i9dLlR6p7+zivIwEAAKCeKGdAC/He/I363Wtz1Ss5QS9efoRSEmO8jgQAAIAGoJwBLcC/Z63VrW/N02Fp7fTsJYcrKTbS60gAAABoIMoZEOKe/nKl7p22SMf26ainxg9XXBT/rAEAAEJRq38Xt3Z7keKjI9Q+PsrrKECDOOf08EdL9einy3XGoM56+Lyhio4I9zoWAAAADlCrLmc+n9M1WbOVV1yhZy7OVJ9OzGqH0ODzOd09ZYFe+GaNzsvsrvvOHaTwMPM6FgAAAA5CmNcBvBQWZrrnrENVVFapcx//Wp8t2eJ1JGC/yit9+uMbP+qFb9ZownE99cDPKWYAAAAtQasuZ5J0WFo7vXPd0erePk6XP/+9nvlqlZxzXscCalVSXqlrXp6jt+eu102n9tWfTu8nM4oZAABAS9Dqy5kkdW0bqzevGamTB3TSPVMX6ra356uswud1LGAPBaUVuvS57/Xxos2656yB+s2JvSlmAAAALQjlLCAuKkJPjBuu35zYS6/OXKvxz3ynHYVlXscCJEk7Css07l/faubq7XrkvKEaPzLD60gAAABoZJSzasLCTDed2k8PnzdEc9fu1NmPz9DyLflex0Irtym3RL966hst3pSvpy4crrMP6+Z1JAAAADQBylktzjksVa9eOUKFpRU657Gv9fnSHK8joZVas61Qv3jya23MLdELlx2hkwZ08joSAAAAmgjlrA7D09vpf9cdo9T2cbr0uZl6bgYThaB5Ld6Up188+Y0KSyv0ypVHakTPDl5HAgAAQBOinO1Dt7axevPqkRrVv5PunrJQt739k8ormSgETW9O9g6d99S3CjfTv68aqcGpbb2OBAAAgCZGOduP+OgIPXXhcF1zQi+9OjNbFz0zUzuLmCgETeerZVt14dPfqW1cpN64eiQnRwcAAGglKGf1EBZmuuW0fvrbr4Zo9podOvuxGVq+pcDrWGiB3v9poy57/nultY/TG1ePVPf2cV5HAgAAQDOhnDXAucNS9eqEI1VQWqFzHp+hL5goBI1kw85i/f3jZbo2a44O7dZGr08YqZTEGK9jAQAAoBlZc05ykZmZ6WbNmtVs99dU1u0o0hUvzNKyLQX6vzEDdNHIdE4GjAbbVlCqd3/apHd+WK/vV++QJJ08oJP+fv5QxUVFeJwOAAAATcHMZjvnMmtbxzvAA5DaLk5vXnOUbnjtB935zgIt3Zyvu84cqMhwBiKxb/kl5fpwwWa98+MGfbV8qyp9Tn1SEnTjKYdo7JCuSu8Q73VEAAAAeIRydoASoiP01PjhevCDxXrq85VatbVQj48bprZxUV5HQ5ApKa/U9CU5eufH9fpk0RaVVvjUrW2sJhzXU2cO6ap+nRMZeQUAAADl7GCEh5n+dHp/9UlJ1G3/ma9zHv9aT1+cqV7JCV5Hg8cqKn36esX/b+/eo7uu7zuOP98kIISrJAEaCLcQqkjlIjjBhna1ttYiaLfTaqXS1a4XamfX7nS1tnVtZ9ez7WzdVrWz2upZ0Z4eqwXtTdutkyKdFyRcpDUgyCUISRCEBCWQz/74ZQxRSBDI9/cjz8c5HH6XQ/I653NIfq/f5/N9/5pYXFvPL1e/wJ5XDlDWrxdXTq9kzuThTB05yEImSZKkV7GcnQR/et4IRpeW8PH/eIorblnKLVdPpaa6POtY6mIpJZZvepHFK+r56aptNO7dT/8zinn3xGHMnVzBjLGlFHv0VZIkSUfhQJCTaPPO3KCQdQ17uemyCVwzY3TWkXSKpZT4/Qt7WFxbz4O19Wx5cR9nFPfgorOHMGfScN7+5nJ69yzKOqYkSZLyhANBukjl4BJ+vGAm19/7NF9ZtIa67bmS5m7J6WdTUwuLa7eyaEU9dTv2UtQjeOu4Mj578XgunjCU/r17Zh1RkiRJBcZydpL1O6OY26+Zxt//4vf8+6O5QSG3fHAqA0t8sV7odrz0Mg+t3Mai2npqN+8CYProM/n65RO5dOIwSvudkXFCSZIkFTLL2SlQ1CO44dKzqRrSjxsfWMUVty7ljvnTGOugkIKzu6WVX6zZxuLaepatb6ItwYQ3DeCG95zF7EkVDB/UJ+uIkiRJOk1Yzk6h90+rZHRpXz7xg6e4/Jal3DbvPC4cV5Z1LHVg3/6D/GrtdhatqOe/n91B68HE6NISrntHNXMmVTBuiCVbkiRJJ58DQbrA5p0tXHv3E6xvaOarc85h3gWjso6kI+w/0MZv1zWwaEU9jzyznZb9Bxk64AwuO7eCOZMreMvwgY6+lyRJ0glzIEjGKgeX8ONPzuT6H67gSz9ZTd32PXx5toNCstbWlnh8404Wrajn56u3saullYF9ejJ38nDmTKrg/DGDKephIZMkSVLXsJx1kf69e/Lda6bxzZ+v5btLNvBcYzPf/uBUBvZxUEhXSimxeutLLFqxlYdWbuOFl16mpFcRF08YypxJFdRUl9Or2NIsSZKkruexxgz86InN3PiTVVQOLuHO+dMZU9Y360invXU79h76LLINjc30LAreNn4IcyZX8M6zh1DSy/cpJEmSdOp5rDHPvH96JaNKSw4bFDKVmVUOCjnZ6nft48HaehbX1rOm/iUiYMbYUj4+ayyXTBzGoJJeWUeUJEmSDnHnLEObmnKDQjY0NvPVuedw9hsNYQAACwBJREFU9R85KORE7Wzez09XbePBFfU8vnEnAJMqBzFnUgWzz30TQwf0zjihJEmSujN3zvLUyNIS7l8wk0/f+zQ3PrCauu17+dJ7z3ZQyHHa+8oBHl7zAotr61lS18jBtkT1kH587uLxXDapgtEeG5UkSVIBsJxlrH/vntw5fzrf+Nla7vxtblDIv101xUEhHXi59SC/+UMDD9bW86u123nlQBvDB/Xhz2vGMndyBWcN6+/oe0mSJBUUy1keKOoRfHn2BKqH9ONLP1nN+25dyp3zp7vjc4SdzftZuq6R3/yhgYfXvMCeVw5Q2rcXH5heydzJFUypPJMejr6XJElSgbKc5ZErzx/JqNK+fHLhU1x+61Juu/o8ZlSVZh0rM/sPtLF804ssqWtgSV0jq7buJiUY0LuYd50zjLmTK5hZVeoxUEmSJJ0WOj0QJCKKgCeBrSml2RGxEJgGtAKPAx9PKbUe62s4EKRznm9q5tq7n2RjYzNfv3wiV50/MutIXSKlxHONzSx5NlfGlj3XRMv+gxT1CKaOHERNdTk11WWcO2KQHw4tSZKkgnSyBoJcD6wFBrTfXwjMa799D/BR4LY3GlL/b1RpX+5fMJPr7nmaG+5fRd32vXzx0rNOyx2iXS37Wbqu6dDu2NZd+wAYXVrCn0wdQU11GTOqSunf22vwJEmSdHrrVDmLiBHAe4Gbgc8CpJR+dtjzjwMjTkXA7mpA7558b/40bv7ZWr63dAPPNe7lX6+awoACLymtB9t4etMultQ18GhdIyu37CIl6N+7mAuryljwx1XUjCtnZGlJ1lElSZKkLtXZnbNvAZ8H+h/5RET0BD5EbmftNSLiY8DHAEaO7B7H806W4qIe3HTZOVQP6c9XFq3mfbc+xp3zpzGqtHAGhaSU2NjUkitjzzaybH0jze1HFSdXDuL6i6qpqS5n0oiBp+XOoCRJktRZHV5zFhGzgUtTSgsi4u3AX6WUZh/2/HeB5pTSZzr6Zl5z9sY9tr6RBQuXE8Bt887jgrH5Oyhkd0srj61v5NG6RpbUNbDlxdxRxcrBfZhVXU5NdTkzqkr9uABJkiR1O8e65qwz5ezvyO2MHQB6k7vm7P6U0ryIuAmYArwvpdTWURDL2YnZ2NjMtXc/wfNNLdx8xUQ+MD0/diJbD7ZRu3nXoTJWu3kXbQn6n1HMjKpSasaXM6u6rKB2/CRJkqRT4YTK2RFf6O2075xFxEeBjwAXpZT2debfW85O3O59rVx3z3KW1DXy0beO4YZLz85kcuHzTc25MvZsA8vWN7HnlQP0CJhUmZuqOKu6jEmVg+jpUUVJkiTpkJM1rfFI3wGeB5ZFBOR20752Al9PnTCwT0++/+Hp/O1P13LHbzewviE3KORUTzN86eVWHjtsquKmnS0ADB/Uh9mTKphVXcbMqjIGlnhUUZIkSXojjmvn7ES5c3Zy/eB3z3PT4jVUlffljmumn9QJhwcOtlG7ZfehMrZi8y4OtiX69ipiRlUZs8aXUVNdzujSEtrLuSRJkqQOnLRjjSfKcnbyPbaukU8uXE5Rj+A7887j/DGD3/DX2ryzhUfrGljybCNL1zey5+UDRMC5IwYxqzpXxqaM9KiiJEmS9EZZzk5zGxqbufauJ9j8Ygs3X/EW3j+tslP/bs/LrSxb38SS9kEeG5tyRxUrBvZm1vjcVMWZVaWc2bfXqYwvSZIkdRun6poz5YkxZX15YMGFfOqe5Xz+vpWs27GXv77krNcMCjnYlli5ZdehMrZ8U+6oYkmvImaMLeXDM0dTM76csWV9PaooSZIkdTHL2WliYElP7vqz6Xz9oWe4/dHnWL9jL9+6cjK797UeKmNL1zWxe18rEfCW4QP5xNvGUlNdztSRZ9Kr2KOKkiRJUpYsZ6eR4qIefHXuRMYN7c/fLF7DBd/4Nc37DwIwbEBv3n3OUGqqy7lwXBmDPaooSZIk5RXL2WnoQxeMoqqsLz96cnNumMf4MqrK+3lUUZIkScpjlrPT1MxxZcwcV5Z1DEmSJEmd5IVGkiRJkpQHLGeSJEmSlAcsZ5IkSZKUByxnkiRJkpQHLGeSJEmSlAcsZ5IkSZKUByxnkiRJkpQHLGeSJEmSlAcsZ5IkSZKUByxnkiRJkpQHLGeSJEmSlAcsZ5IkSZKUByxnkiRJkpQHIqXUdd8sogF4vsu+YeeVAY1Zh9Bxcc0Ki+tVeFyzwuOaFR7XrLC4XoUnX9dsVEqp/PWe6NJylq8i4smU0rSsc6jzXLPC4noVHtes8Lhmhcc1KyyuV+EpxDXzWKMkSZIk5QHLmSRJkiTlActZzu1ZB9Bxc80Ki+tVeFyzwuOaFR7XrLC4XoWn4NbMa84kSZIkKQ+4cyZJkiRJecByJkmSJEl5oFuXs4i4JCL+EBHrIuILWefRsUVEZUT8V0Q8ExFrIuL6rDOpcyKiKCKejoiHss6ijkXEoIi4LyJ+HxFrI2JG1pl0dBHxl+0/E1dHxL0R0TvrTHq1iPheROyIiNWHPTY4Ih6JiLr2v8/MMqNe7Shr9g/tPxdXRsQDETEoy4x6tddbs8Oe+1xEpIgoyyLb8ei25SwiioBbgPcAE4CrImJCtqnUgQPA51JKE4ALgE+5ZgXjemBt1iHUaf8C/CKldBYwCdcub0XEcOAvgGkppYlAEXBltqn0Ou4CLjnisS8Av04pVQO/br+v/HEXr12zR4CJKaVzgWeBG7o6lI7pLl67ZkREJfAuYFNXB3ojum05A84H1qWUnksp7Qd+CMzNOJOOIaW0LaW0vP32HnIvGIdnm0odiYgRwHuBO7LOoo5FxEBgFnAnQEppf0ppV7ap1IFioE9EFAMlQH3GeXSElNKjwM4jHp4L3N1++27g8i4NpWN6vTVLKT2cUjrQfvd3wIguD6ajOsr/M4B/Bj4PFMQUxO5czoYDmw+7vwVf6BeMiBgNTAH+J9sk6oRvkfuh2JZ1EHXKGKAB+H77UdQ7IqJv1qH0+lJKW4F/JPeO8DZgd0rp4WxTqZOGppS2td9+ARiaZRgdt48AP886hI4tIuYCW1NKtVln6azuXM5UoCKiH/Bj4DMppZeyzqOji4jZwI6U0lNZZ1GnFQNTgdtSSlOAZjxulbfar1OaS65UVwB9I2Jetql0vFLuc40K4l19QUTcSO5Si4VZZ9HRRUQJ8EXgK1lnOR7duZxtBSoPuz+i/THlsYjoSa6YLUwp3Z91HnXoQmBORGwkd3T4HRHxg2wjqQNbgC0ppf/blb6PXFlTfnonsCGl1JBSagXuB2ZmnEmdsz0i3gTQ/veOjPOoEyLiw8Bs4OrkhwXnuypyb1zVtr8OGQEsj4hhmabqQHcuZ08A1RExJiJ6kbuAenHGmXQMERHkroNZm1L6p6zzqGMppRtSSiNSSqPJ/R/7z5SS7+rnsZTSC8DmiHhz+0MXAc9kGEnHtgm4ICJK2n9GXoQDXArFYmB+++35wKIMs6gTIuIScsf056SUWrLOo2NLKa1KKQ1JKY1ufx2yBZja/nsub3XbctZ+Qed1wC/J/SL7UUppTbap1IELgQ+R231Z0f7n0qxDSaehTwMLI2IlMBn4RsZ5dBTtO5z3AcuBVeR+r9+eaSi9RkTcCywD3hwRWyLiWuCbwMURUUduB/SbWWbUqx1lzb4N9AceaX8N8p1MQ+pVjrJmBSfckZUkSZKk7HXbnTNJkiRJyieWM0mSJEnKA5YzSZIkScoDljNJkiRJygOWM0mSJEnKA5YzSZIkScoDljNJkiRJygP/C++gaoRffuM0AAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "plt.cla()\n",
        "env.render_all()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Reinforcement learning for Trading.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
